# @package config

lr: 2e-5
seed: 123
gradient_accumulation_steps: 1
weight_decay: 0.01
validation_metrics: [ MRR@10, recall@100, recall@200, recall@500 ]
pretrained_no_yamlconfig: false
nb_iterations: 150000

#train_batch_size: 128  # number of gpus needs to divide this
#eval_batch_size: 600
#index_retrieve_batch_size: 500

train_batch_size: 16  # number of gpus needs to divide this
eval_batch_size: 16
index_retrieve_batch_size: 16

record_frequency: 10000
train_monitoring_freq: 500
warmup_steps: 6000
max_length: 256

#fp16: true

fp16: false
matching_type: splade
monitoring_ckpt: MRR@10  # or e.g. MRR@10

loss: InBatchPairwiseNLL
regularizer:
  FLOPS:
    lambda_q: 5e-4
    lambda_d: 3e-4
    T: 3
    targeted_rep: rep
    reg: FLOPS
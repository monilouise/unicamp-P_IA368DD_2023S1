{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyitPdpgpMSC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPLADE for Portuguese\n",
        "\n",
        "Inspired by https://github.com/naver/splade"
      ],
      "metadata": {
        "id": "5cnpWkkZpYHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/naver/splade.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUahc3O8pbF7",
        "outputId": "6d30c380-07c0-46d6-e820-f93f419322ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "hydra-core 1.3.2 requires antlr4-python3-runtime==4.9.*, but you have antlr4-python3-runtime 4.8 which is incompatible.\n",
            "hydra-core 1.3.2 requires omegaconf<2.4,>=2.2, but you have omegaconf 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hydra-core --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "ooQjeuIjq9RG",
        "outputId": "c5b7e6a6-156d-420e-f196-8b4567287c11"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core)\n",
            "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core)\n",
            "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core) (23.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0)\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
            "  Attempting uninstall: antlr4-python3-runtime\n",
            "    Found existing installation: antlr4-python3-runtime 4.8\n",
            "    Uninstalling antlr4-python3-runtime-4.8:\n",
            "      Successfully uninstalled antlr4-python3-runtime-4.8\n",
            "  Attempting uninstall: omegaconf\n",
            "    Found existing installation: omegaconf 2.1.2\n",
            "    Uninstalling omegaconf-2.1.2:\n",
            "      Successfully uninstalled omegaconf-2.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "splade 2.1 requires omegaconf==2.1.2, but you have omegaconf 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytrec_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dyw4zU3s-Jw",
        "outputId": "a1f76f75-9808-4947-8b4b-dbd1502e486b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytrec_eval\n",
            "  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pytrec_eval\n",
            "  Building wheel for pytrec_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrec_eval: filename=pytrec_eval-0.5-cp310-cp310-linux_x86_64.whl size=293453 sha256=819e564284a5d34f3ca801637bfebb93bea3b6722ed8006abad94967b5705a64\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3a/cd/dcc1ddfc763987d5cb237165d8ac249aa98a23ab90f67317a8\n",
            "Successfully built pytrec_eval\n",
            "Installing collected packages: pytrec_eval\n",
            "Successfully installed pytrec_eval-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CONFIG_NAME = None\n",
        "CONFIG_PATH = \"../conf\"\n",
        "\n",
        "##############################################################\n",
        "# Provide (as env var), either:\n",
        "# * 'SPLADE_CONFIG_NAME', this config in splade/conf will be used\n",
        "# * or 'SPLADE_CONFIG_FULLPATH' (full path, from an exp, such as '/my/path/to/exp/config.yaml'\n",
        "\n",
        "# if nothing is provided, 'config_default' is used\n",
        "##############################################################\n",
        "\n",
        "assert sum([v in os.environ.keys() for v in [\"SPLADE_CONFIG_NAME\", \"SPLADE_CONFIG_FULLPATH\"]]) <= 1\n",
        "\n",
        "if \"SPLADE_CONFIG_NAME\" in os.environ.keys():\n",
        "    CONFIG_NAME = os.environ[\"SPLADE_CONFIG_NAME\"]\n",
        "elif \"SPLADE_CONFIG_FULLPATH\" in os.environ.keys():\n",
        "    CONFIG_FULLPATH = os.environ[\"SPLADE_CONFIG_FULLPATH\"]\n",
        "    CONFIG_PATH, CONFIG_NAME = os.path.split(CONFIG_FULLPATH)\n",
        "else:\n",
        "    CONFIG_NAME = \"config_default\"\n",
        "\n",
        "if \".yaml\" in CONFIG_NAME:\n",
        "    CONFIG_NAME = CONFIG_NAME.split(\".yaml\")[0]\n"
      ],
      "metadata": {
        "id": "43phOBEps1CA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import hydra\n",
        "import torch\n",
        "from omegaconf import DictConfig, open_dict\n",
        "from torch.utils import data\n",
        "\n",
        "from splade.datasets.dataloaders import CollectionDataLoader, SiamesePairsDataLoader, DistilSiamesePairsDataLoader\n",
        "from splade.datasets.datasets import PairsDatasetPreLoad, DistilPairsDatasetPreLoad, MsMarcoHardNegatives, \\\n",
        "    CollectionDatasetPreLoad\n",
        "from splade.losses.regularization import init_regularizer, RegWeightScheduler\n",
        "from splade.models.models_utils import get_model\n",
        "from splade.optim.bert_optim import init_simple_bert_optim\n",
        "from splade.tasks.transformer_evaluator import SparseApproxEvalWrapper\n",
        "from splade.tasks.transformer_trainer import SiameseTransformerTrainer\n",
        "from splade.utils.utils import set_seed, restore_model, get_initialize_config, get_loss, set_seed_from_config"
      ],
      "metadata": {
        "id": "-DL5KUpYq5B3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@hydra.main(config_path=CONFIG_PATH, config_name=CONFIG_NAME)\n",
        "def train(exp_dict: DictConfig):\n",
        "    exp_dict, config, init_dict, _ = get_initialize_config(exp_dict, train=True)\n",
        "    model = get_model(config, init_dict)\n",
        "    random_seed = set_seed_from_config(config)\n",
        "\n",
        "    optimizer, scheduler = init_simple_bert_optim(model, lr=config[\"lr\"], warmup_steps=config[\"warmup_steps\"],\n",
        "                                                  weight_decay=config[\"weight_decay\"],\n",
        "                                                  num_training_steps=config[\"nb_iterations\"])\n",
        "\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "    ################################################################\n",
        "    # CHECK IF RESUME TRAINING\n",
        "    ################################################################\n",
        "    iterations = (1, config[\"nb_iterations\"] + 1)  # tuple with START and END\n",
        "    regularizer = None\n",
        "    if os.path.exists(os.path.join(config[\"checkpoint_dir\"], \"model_ckpt/model_last.tar\")):\n",
        "        print(\"@@@@ RESUMING TRAINING @@@\")\n",
        "        print(\"WARNING: change seed to change data order when restoring !\")\n",
        "        set_seed(random_seed + 666)\n",
        "        if device == torch.device(\"cuda\"):\n",
        "            ckpt = torch.load(os.path.join(config[\"checkpoint_dir\"], \"model_ckpt/model_last.tar\"))\n",
        "        else:\n",
        "            ckpt = torch.load(os.path.join(config[\"checkpoint_dir\"], \"model_ckpt/model_last.tar\"), map_location=device)\n",
        "        print(\"starting from step\", ckpt[\"step\"])\n",
        "        print(\"{} remaining iterations\".format(iterations[1] - ckpt[\"step\"]))\n",
        "        iterations = (ckpt[\"step\"] + 1, config[\"nb_iterations\"])\n",
        "        restore_model(model, ckpt[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
        "        if device == torch.device(\"cuda\"):\n",
        "            for state in optimizer.state.values():\n",
        "                for k, v in state.items():\n",
        "                    if torch.is_tensor(v):\n",
        "                        state[k] = v.cuda()\n",
        "        scheduler.load_state_dict(ckpt[\"scheduler_state_dict\"])\n",
        "        if \"regularizer\" in ckpt:\n",
        "            print(\"loading regularizer\")\n",
        "            regularizer = ckpt.get(\"regularizer\", None)\n",
        "\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(\" --- use {} GPUs --- \".format(torch.cuda.device_count()))\n",
        "        model = torch.nn.DataParallel(model)\n",
        "    model.to(device)\n",
        "\n",
        "    loss = get_loss(config)\n",
        "\n",
        "    # initialize regularizer dict\n",
        "    if \"regularizer\" in config and regularizer is None:  # else regularizer is loaded\n",
        "        output_dim = model.module.output_dim if hasattr(model, \"module\") else model.output_dim\n",
        "        regularizer = {\"eval\": {\"L0\": {\"loss\": init_regularizer(\"L0\")},\n",
        "                                \"sparsity_ratio\": {\"loss\": init_regularizer(\"sparsity_ratio\",\n",
        "                                                                            output_dim=output_dim)}},\n",
        "                       \"train\": {}}\n",
        "        if config[\"regularizer\"] == \"eval_only\":\n",
        "            # just in the case we train a model without reg but still want the eval metrics like L0\n",
        "            pass\n",
        "        else:\n",
        "            for reg in config[\"regularizer\"]:\n",
        "                temp = {\"loss\": init_regularizer(config[\"regularizer\"][reg][\"reg\"]),\n",
        "                        \"targeted_rep\": config[\"regularizer\"][reg][\"targeted_rep\"]}\n",
        "                d_ = {}\n",
        "                if \"lambda_q\" in config[\"regularizer\"][reg]:\n",
        "                    d_[\"lambda_q\"] = RegWeightScheduler(config[\"regularizer\"][reg][\"lambda_q\"],\n",
        "                                                        config[\"regularizer\"][reg][\"T\"])\n",
        "                if \"lambda_d\" in config[\"regularizer\"][reg]:\n",
        "                    d_[\"lambda_d\"] = RegWeightScheduler(config[\"regularizer\"][reg][\"lambda_d\"],\n",
        "                                                        config[\"regularizer\"][reg][\"T\"])\n",
        "                temp[\"lambdas\"] = d_  # it is possible to have reg only on q or d if e.g. you only specify lambda_q\n",
        "                # in the reg config\n",
        "                # targeted_rep is just used to indicate which rep to constrain (if e.g. the model outputs several\n",
        "                # representations)\n",
        "                # the common case: model outputs \"rep\" (in forward) and this should be the value for this targeted_rep\n",
        "                regularizer[\"train\"][reg] = temp\n",
        "\n",
        "    # fix for current in batch neg losses that break on last batch\n",
        "    if config[\"loss\"] in (\"InBatchNegHingeLoss\", \"InBatchPairwiseNLL\"):\n",
        "        drop_last = True\n",
        "    else:\n",
        "        drop_last = False\n",
        "\n",
        "    if exp_dict[\"data\"].get(\"type\", \"\") == \"triplets\":\n",
        "        data_train = PairsDatasetPreLoad(data_dir=exp_dict[\"data\"][\"TRAIN_DATA_DIR\"])\n",
        "        train_mode = \"triplets\"\n",
        "    elif exp_dict[\"data\"].get(\"type\", \"\") == \"triplets_with_distil\":\n",
        "        data_train = DistilPairsDatasetPreLoad(data_dir=exp_dict[\"data\"][\"TRAIN_DATA_DIR\"])\n",
        "        train_mode = \"triplets_with_distil\"\n",
        "    elif exp_dict[\"data\"].get(\"type\", \"\") == \"hard_negatives\":\n",
        "        data_train = MsMarcoHardNegatives(\n",
        "            dataset_path=exp_dict[\"data\"][\"TRAIN\"][\"DATASET_PATH\"],\n",
        "            document_dir=exp_dict[\"data\"][\"TRAIN\"][\"D_COLLECTION_PATH\"],\n",
        "            query_dir=exp_dict[\"data\"][\"TRAIN\"][\"Q_COLLECTION_PATH\"],\n",
        "            qrels_path=exp_dict[\"data\"][\"TRAIN\"][\"QREL_PATH\"])\n",
        "        train_mode = \"triplets_with_distil\"\n",
        "    else:\n",
        "        raise ValueError(\"provide valid data type for training\")\n",
        "\n",
        "    val_loss_loader = None  # default\n",
        "    if \"VALIDATION_SIZE_FOR_LOSS\" in exp_dict[\"data\"]:\n",
        "        print(\"initialize loader for validation loss\")\n",
        "        print(\"split train, originally {} pairs\".format(len(data_train)))\n",
        "        data_train, data_val = torch.utils.data.random_split(data_train, lengths=[\n",
        "            len(data_train) - exp_dict[\"data\"][\"VALIDATION_SIZE_FOR_LOSS\"],\n",
        "            exp_dict[\"data\"][\"VALIDATION_SIZE_FOR_LOSS\"]])\n",
        "        print(\"train: {} pairs ~~ val: {} pairs\".format(len(data_train), len(data_val)))\n",
        "        if train_mode == \"triplets\":\n",
        "            val_loss_loader = SiamesePairsDataLoader(dataset=data_val, batch_size=config[\"eval_batch_size\"],\n",
        "                                                     shuffle=False,\n",
        "                                                     num_workers=4,\n",
        "                                                     tokenizer_type=config[\"tokenizer_type\"],\n",
        "                                                     max_length=config[\"max_length\"], drop_last=drop_last)\n",
        "        elif train_mode == \"triplets_with_distil\":\n",
        "            val_loss_loader = DistilSiamesePairsDataLoader(dataset=data_val, batch_size=config[\"eval_batch_size\"],\n",
        "                                                           shuffle=False,\n",
        "                                                           num_workers=4,\n",
        "                                                           tokenizer_type=config[\"tokenizer_type\"],\n",
        "                                                           max_length=config[\"max_length\"], drop_last=drop_last)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    if train_mode == \"triplets\":\n",
        "        train_loader = SiamesePairsDataLoader(dataset=data_train, batch_size=config[\"train_batch_size\"], shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              tokenizer_type=config[\"tokenizer_type\"],\n",
        "                                              max_length=config[\"max_length\"], drop_last=drop_last)\n",
        "    elif train_mode == \"triplets_with_distil\":\n",
        "        train_loader = DistilSiamesePairsDataLoader(dataset=data_train, batch_size=config[\"train_batch_size\"],\n",
        "                                                    shuffle=True,\n",
        "                                                    num_workers=4,\n",
        "                                                    tokenizer_type=config[\"tokenizer_type\"],\n",
        "                                                    max_length=config[\"max_length\"], drop_last=drop_last)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    val_evaluator = None\n",
        "    if \"VALIDATION_FULL_RANKING\" in exp_dict[\"data\"]:\n",
        "        with open_dict(config):\n",
        "            config[\"val_full_rank_qrel_path\"] = exp_dict[\"data\"][\"VALIDATION_FULL_RANKING\"][\"QREL_PATH\"]\n",
        "        full_ranking_d_collection = CollectionDatasetPreLoad(\n",
        "            data_dir=exp_dict[\"data\"][\"VALIDATION_FULL_RANKING\"][\"D_COLLECTION_PATH\"], id_style=\"row_id\")\n",
        "        full_ranking_d_loader = CollectionDataLoader(dataset=full_ranking_d_collection,\n",
        "                                                     tokenizer_type=config[\"tokenizer_type\"],\n",
        "                                                     max_length=config[\"max_length\"],\n",
        "                                                     batch_size=config[\"eval_batch_size\"],\n",
        "                                                     shuffle=False, num_workers=4)\n",
        "        full_ranking_q_collection = CollectionDatasetPreLoad(\n",
        "            data_dir=exp_dict[\"data\"][\"VALIDATION_FULL_RANKING\"][\"Q_COLLECTION_PATH\"], id_style=\"row_id\")\n",
        "        full_ranking_q_loader = CollectionDataLoader(dataset=full_ranking_q_collection,\n",
        "                                                     tokenizer_type=config[\"tokenizer_type\"],\n",
        "                                                     max_length=config[\"max_length\"], batch_size=1,\n",
        "                                                     # TODO fix: bs currently set to 1\n",
        "                                                     shuffle=False, num_workers=4)\n",
        "        val_evaluator = SparseApproxEvalWrapper(model,\n",
        "                                                config={\"top_k\": exp_dict[\"data\"][\"VALIDATION_FULL_RANKING\"][\"TOP_K\"],\n",
        "                                                        \"out_dir\": os.path.join(config[\"checkpoint_dir\"],\n",
        "                                                                                \"val_full_ranking\")\n",
        "                                                        },\n",
        "                                                collection_loader=full_ranking_d_loader,\n",
        "                                                q_loader=full_ranking_q_loader,\n",
        "                                                restore=False)\n",
        "\n",
        "    # #################################################################\n",
        "    # # TRAIN\n",
        "    # #################################################################\n",
        "    print(\"+++++ BEGIN TRAINING +++++\")\n",
        "    trainer = SiameseTransformerTrainer(model=model, iterations=iterations, loss=loss, optimizer=optimizer,\n",
        "                                        config=config, scheduler=scheduler,\n",
        "                                        train_loader=train_loader, validation_loss_loader=val_loss_loader,\n",
        "                                        validation_evaluator=val_evaluator,\n",
        "                                        regularizer=regularizer)\n",
        "    trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7KHK41Gq6P3",
        "outputId": "203fd00f-2b3d-4b6c-c50c-f4fb6885ee39"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-0b2ab76c077c>:1: UserWarning: \n",
            "The version_base parameter is not specified.\n",
            "Please specify a compatability version level, or None.\n",
            "Will assume defaults for version 1.1\n",
            "  @hydra.main(config_path=CONFIG_PATH, config_name=CONFIG_NAME)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "UUhxzjxdtSUm",
        "outputId": "d80bcc48-9716-4e41-c168-a7fb897fedc2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [--help] [--hydra-help] [--version]\n",
            "                             [--cfg {job,hydra,all}] [--resolve]\n",
            "                             [--package PACKAGE] [--run] [--multirun]\n",
            "                             [--shell-completion] [--config-path CONFIG_PATH]\n",
            "                             [--config-name CONFIG_NAME]\n",
            "                             [--config-dir CONFIG_DIR]\n",
            "                             [--experimental-rerun EXPERIMENTAL_RERUN]\n",
            "                             [--info [{all,config,defaults,defaults-tree,plugins,searchpath}]]\n",
            "                             [overrides ...]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIXjUL7ZtT8q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
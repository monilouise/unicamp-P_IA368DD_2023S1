{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "2FtZGrPKuTwP",
        "-RLVOaq8TUJL"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eNsv97ytgGF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Buscador booleano/bag-of-words no TREC-DL 2020"
      ],
      "metadata": {
        "id": "bDiqaFQPuNar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui, é implementado um buscador booleano, que apenas leva em consideração a ocorrência ou não de cada termo da query em cada documento, independente do número de ocorrências de cada termo (abordagem bag-of-words)."
      ],
      "metadata": {
        "id": "Gxw_ExbPU6K9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download do dataset"
      ],
      "metadata": {
        "id": "2FtZGrPKuTwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkWo-SJ3uUe-",
        "outputId": "a09ea891-27f6-4024-d20b-0b3ad031c671"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_path = '/content/drive/MyDrive/Unicamp-aula-2/'\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(main_path):\n",
        "  os.makedirs(main_path)\n",
        "else:\n",
        "  print('Diretório já existente')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLcUasvzuXPB",
        "outputId": "731fa587-3381-4773-e71e-7e0d0e18a042"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diretório já existente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download de ferramentas auxiliares"
      ],
      "metadata": {
        "id": "-RLVOaq8TUJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyserini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be_swSbxurh7",
        "outputId": "6829bff1-9388-4ad9-ffca-0c6e25bdad99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyserini\n",
            "  Downloading pyserini-0.20.0-py3-none-any.whl (137.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.1/137.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece>=0.1.95\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=1.4.0\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightgbm>=3.3.2\n",
            "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.8.1\n",
            "  Downloading onnxruntime-1.14.1-cp38-cp38-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pyserini) (4.64.1)\n",
            "Requirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (3.4.4)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.22.4)\n",
            "Collecting pyjnius>=1.4.0\n",
            "  Downloading pyjnius-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.2.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.10.1)\n",
            "Collecting transformers>=4.6.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.8/dist-packages (from pyserini) (0.29.33)\n",
            "Collecting nmslib>=2.1.1\n",
            "  Downloading nmslib-2.1.1-cp38-cp38-manylinux2010_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=3.3.2->pyserini) (0.38.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.1.21)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.7.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.19.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.4.0->pyserini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.4.0->pyserini) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.0.8)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.4.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.10.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (8.1.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.25.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.0.12)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.1.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (6.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.6.0->pyserini) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.26.14)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.2.1->pyserini) (8.1.3)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.2.1)\n",
            "Installing collected packages: tokenizers, sentencepiece, pyjnius, pybind11, humanfriendly, pandas, nmslib, huggingface-hub, coloredlogs, transformers, onnxruntime, lightgbm, pyserini\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed coloredlogs-15.0.1 huggingface-hub-0.12.1 humanfriendly-10.0 lightgbm-3.3.5 nmslib-2.1.1 onnxruntime-1.14.1 pandas-1.5.3 pybind11-2.6.1 pyjnius-1.4.2 pyserini-0.20.0 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/castorini/pyserini.git --recurse-submodules {main_path}/pyserini"
      ],
      "metadata": {
        "id": "O97kuBrZTyZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd {main_path}/pyserini/tools/eval && tar xvfz trec_eval.9.0.4.tar.gz && cd trec_eval.9.0.4 && make && cd ../../..\n",
        "!cd {main_path}/pyserini/tools/eval/ndeval && make && cd ../../.."
      ],
      "metadata": {
        "id": "OjR4FDswUJeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção do índice invertido"
      ],
      "metadata": {
        "id": "ZmvMxtynTmKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyserini.analysis import Analyzer, get_lucene_analyzer"
      ],
      "metadata": {
        "id": "cCpsvCE7u0o7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSMFneIku5L3",
        "outputId": "fb8066e3-cc08-49b1-a2c7-9bb9b05b6110"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = Analyzer(get_lucene_analyzer(stemmer='porter'))\n",
        "\n",
        "def preprocess_and_tokenize(text):\n",
        "  return analyzer.analyze(text)"
      ],
      "metadata": {
        "id": "49JWfNjWu8ZJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "collection_path = main_path + '/collections/msmarco-passage/collection.tsv'\n",
        "\n"
      ],
      "metadata": {
        "id": "kwy8QAUCvBi1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "nltk.download('stopwords')  # Download stopwords if not already downloaded\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words = set(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhc11tGLJPWe",
        "outputId": "aa982f83-9d11-447c-91fd-c03fc9ce5bb3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "#df_collection = pd.read_csv('collections/msmarco-passage/collection.tsv', sep='\\t', header=None)\n",
        "\n",
        "# set the chunk size\n",
        "chunk_size = 1000\n",
        "chunks = []\n",
        "inverted_index = defaultdict(set)\n",
        "full_text = ''\n",
        "\n",
        "def process(row):\n",
        "  tokenized_text = preprocess_and_tokenize(row[1])\n",
        "  doc_id = row[0]\n",
        "  for token in tokenized_text:\n",
        "    #teste para reduzir o índice\n",
        "    if token not in stop_words:\n",
        "      inverted_index[token].add(doc_id)\n",
        "\n",
        "chunk_id = 0\n",
        "# iterate through the file in chunks\n",
        "for chunk in pd.read_csv(collection_path, sep='\\t', header=None, chunksize=chunk_size):\n",
        "  # process the chunk here\n",
        "  if (chunk_id % 1000) == 0:\n",
        "    print(f'Processing chunk {chunk_id}')\n",
        "  for index, row in chunk.iterrows():\n",
        "    #full_text = process2(row, full_text)\n",
        "    process(row)\n",
        "  del(chunk)\n",
        "  chunk_id += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8GurqwF5yhX",
        "outputId": "156300e2-11b0-4d63-b4cb-1ea482d63f73"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing chunk 0\n",
            "Processing chunk 1000\n",
            "Processing chunk 2000\n",
            "Processing chunk 3000\n",
            "Processing chunk 4000\n",
            "Processing chunk 5000\n",
            "Processing chunk 6000\n",
            "Processing chunk 7000\n",
            "Processing chunk 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(inverted_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD1BrbHRvMDL",
        "outputId": "d0204cd9-55d2-47f4-ba25-77709703385e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2660662"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {collection_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqUvI7BC5VHw",
        "outputId": "313d6080-baca-4764-d1f0-9549c3ac121d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\tThe presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.\n",
            "1\tThe Manhattan Project and its atomic bomb helped bring an end to World War II. Its legacy of peaceful uses of atomic energy continues to have an impact on history and science.\n",
            "2\tEssay on The Manhattan Project - The Manhattan Project The Manhattan Project was to see if making an atomic bomb possible. The success of this project would forever change the world forever making it known that something this powerful can be manmade.\n",
            "3\tThe Manhattan Project was the name for a project conducted during World War II, to develop the first atomic bomb. It refers specifically to the period of the project from 194 â¦ 2-1946 under the control of the U.S. Army Corps of Engineers, under the administration of General Leslie R. Groves.\n",
            "4\tversions of each volume as well as complementary websites. The first websiteâThe Manhattan Project: An Interactive Historyâis available on the Office of History and Heritage Resources website, http://www.cfo. doe.gov/me70/history. The Office of History and Heritage Resources and the National Nuclear Security\n",
            "5\tThe Manhattan Project. This once classified photograph features the first atomic bomb â a weapon that atomic scientists had nicknamed Gadget.. The nuclear age began on July 16, 1945, when it was detonated in the New Mexico desert.\n",
            "6\tNor will it attempt to substitute for the extraordinarily rich literature on the atomic bombs and the end of World War II. This collection does not attempt to document the origins and development of the Manhattan Project.\n",
            "7\tManhattan Project. The Manhattan Project was a research and development undertaking during World War II that produced the first nuclear weapons. It was led by the United States with the support of the United Kingdom and Canada. From 1942 to 1946, the project was under the direction of Major General Leslie Groves of the U.S. Army Corps of Engineers. Nuclear physicist Robert Oppenheimer was the director of the Los Alamos Laboratory that designed the actual bombs. The Army component of the project was designated the\n",
            "8\tIn June 1942, the United States Army Corps of Engineersbegan the Manhattan Project- The secret name for the 2 atomic bombs.\n",
            "9\tOne of the main reasons Hanford was selected as a site for the Manhattan Project's B Reactor was its proximity to the Columbia River, the largest river flowing into the Pacific Ocean from the North American coast.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação"
      ],
      "metadata": {
        "id": "K4t5V238T7d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics_file = main_path + '/pyserini/tools/topics-and-qrels/topics.dl20.txt'\n",
        "qrels_eval = main_path + '/pyserini/tools/topics-and-qrels/qrels.dl20-passage.txt'"
      ],
      "metadata": {
        "id": "aiujR-Y6KUtf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head {topics_file}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F0hqvNoLta6",
        "outputId": "ba5d3649-b28d-4829-d4dc-18c32baa123c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1030303\twho is aziz hashim\r\n",
            "1037496\twho is rep scalise?\r\n",
            "1043135\twho killed nicholas ii of russia\r\n",
            "1045109\twho owns barnhart crane\r\n",
            "1049519\twho said no one can make you feel inferior\r\n",
            "1051399\twho sings monk theme song\r\n",
            "1056416\twho was the highest career passer  rating in the nfl\r\n",
            "1064670\twhy do hunters pattern their shotguns?\r\n",
            "1065636\twhy do some places on my scalp feel sore\r\n",
            "1071750\twhy is pete rose banned from hall of fame\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {qrels_eval}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ8H_jWOfBMs",
        "outputId": "5201033c-3d27-4339-b0b5-36c8fceeb708"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23849 0 1020327 2\n",
            "23849 0 1034183 3\n",
            "23849 0 1120730 0\n",
            "23849 0 1139571 1\n",
            "23849 0 1143724 0\n",
            "23849 0 1147202 0\n",
            "23849 0 1150311 0\n",
            "23849 0 1158886 2\n",
            "23849 0 1175024 1\n",
            "23849 0 1201385 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search(query, use_stopwords=False):\n",
        "  doc_scores = defaultdict(int) # int (doc_id) -> int (score)\n",
        "  query_tokens = preprocess_and_tokenize(query)\n",
        "\n",
        "  for token in query_tokens:\n",
        "    if token in inverted_index:\n",
        "      if use_stopwords or token not in stop_words:\n",
        "        doc_ids = inverted_index[token]\n",
        "        for doc_id in doc_ids:\n",
        "          doc_scores[doc_id] += 1\n",
        "\n",
        "  return doc_scores"
      ],
      "metadata": {
        "id": "1VjKwZJMLvgI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = search('who is aziz hashim', True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfHwaJWhNYBF",
        "outputId": "354cd0a3-c6e7-4ba5-a89d-a48857b99552"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['who', 'aziz', 'hashim']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0nNth1oNnNe",
        "outputId": "6bfac55e-cfec-4e24-a447-a885b951195a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "479793"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = search('who is aziz hashim')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn3pLmpuNtq-",
        "outputId": "19f24c4d-ce3f-453c-bd1f-1a4b3aa68efa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['who', 'aziz', 'hashim']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDTItA7uQMUI",
        "outputId": "f20a13aa-2dda-4d3e-b440-2599d05f7831"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "245"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#6989780, 1305521, 4358004, 1815707, 7508059"
      ],
      "metadata": {
        "id": "wualKpHjQOEL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OBS.: A lista de stopwords do Lucene Analyzer parece ser muito retrista.  Assim, para reduzir o tamanho do índice, uma alternativa seria combinar com a lista de stopwords do NLTK - ou seja, só salvar no índie invertido se não estiver na lsita de stopwords do NLTK."
      ],
      "metadata": {
        "id": "bXuqO206Q_Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_document_by_id(id):\n",
        "  result = None\n",
        "  with open(collection_path, 'r') as f:\n",
        "    for line in f:\n",
        "      fields = line.strip().split('\\t')\n",
        "      doc_id = fields[0]\n",
        "      if doc_id == id:\n",
        "        result = fields[1]\n",
        "        break\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "eExn_oy6Wh3w"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)[:10]"
      ],
      "metadata": {
        "id": "A0O3yBIEYXDg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-udZL3mbY32L",
        "outputId": "973bcff2-fd5e-483e-825a-79d3acfd2546"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(7156982, 2),\n",
              " (8726429, 2),\n",
              " (8726430, 2),\n",
              " (8726433, 2),\n",
              " (8726434, 2),\n",
              " (8726435, 2),\n",
              " (8726436, 2),\n",
              " (8726437, 2),\n",
              " (794624, 1),\n",
              " (4820481, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_document_by_id('8726437')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xnUN599MY5XY",
        "outputId": "77514edf-b8f7-4f50-cdf2-e5794984b590"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Aziz Hashim is one of the worldâ\\x80\\x99s leading experts on franchising and a highly regarded executive in the U.S. and international franchise space. He is the Founder and Managing Partner of NRD Capital (NRD), the first business fund both sponsored and managed by a former multi-unit franchisee.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_to_results = dict()\n",
        "\n",
        "with open(topics_file, 'r') as f:\n",
        "  for line in f:\n",
        "      fields = line.strip().split('\\t')\n",
        "      query_id = fields[0]\n",
        "      query_text = fields[1]\n",
        "      results = search(query_text)\n",
        "      query_to_results[int(query_id)] = sorted(results.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "with open('run.dl20.boolean.trec', 'w') as f:\n",
        "  for query_id, results in query_to_results.items():\n",
        "    for i, (doc_id, score) in enumerate(results):\n",
        "      f.write(f'{query_id}\\tQ0\\t{doc_id}\\t{i+1}\\t{score}\\tboolean\\n')"
      ],
      "metadata": {
        "id": "cLL1cRNcZAt2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head run.dl20.boolean.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiRHnKrlFPyw",
        "outputId": "82645a02-eb0b-4a1f-e57e-8764c50af169"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1030303\tQ0\t7156982\t1\t2\tboolean\n",
            "1030303\tQ0\t8726429\t2\t2\tboolean\n",
            "1030303\tQ0\t8726430\t3\t2\tboolean\n",
            "1030303\tQ0\t8726433\t4\t2\tboolean\n",
            "1030303\tQ0\t8726434\t5\t2\tboolean\n",
            "1030303\tQ0\t8726435\t6\t2\tboolean\n",
            "1030303\tQ0\t8726436\t7\t2\tboolean\n",
            "1030303\tQ0\t8726437\t8\t2\tboolean\n",
            "1030303\tQ0\t794624\t9\t1\tboolean\n",
            "1030303\tQ0\t4820481\t10\t1\tboolean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python {main_path}/pyserini/tools/scripts/msmarco/convert_msmarco_to_trec_qrels.py \\\n",
        "   --input {qrels_eval} \\\n",
        "   --output qrels.dl20.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u51xHcmNGJ2i",
        "outputId": "f5d25c2e-7cfd-459f-836b-1cf97912a251"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head qrels.dl20.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtocDxsYHZDV",
        "outputId": "d6d28447-d263-43f9-e802-c41e2ca549e4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23849 0 1020327 2\n",
            "23849 0 1034183 3\n",
            "23849 0 1120730 0\n",
            "23849 0 1139571 1\n",
            "23849 0 1143724 0\n",
            "23849 0 1147202 0\n",
            "23849 0 1150311 0\n",
            "23849 0 1158886 2\n",
            "23849 0 1175024 1\n",
            "23849 0 1201385 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{main_path}/pyserini/tools/eval/trec_eval.9.0.4/trec_eval -c -m map -m ndcg_cut.10 -l 2 \\\n",
        "   qrels.dl20.trec run.dl20.boolean.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMNRIGZZHpu6",
        "outputId": "4b9b01e3-a393-4e99-df91-537029959824"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "map                   \tall\t0.1117\n",
            "ndcg_cut_10           \tall\t0.3189\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eNsv97ytgGF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Buscador booleano/bag-of-words no TREC-DL 2020"
      ],
      "metadata": {
        "id": "bDiqaFQPuNar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui, é implementado um buscador booleano, que apenas leva em consideração a ocorrência ou não de cada termo da query em cada documento, independente do número de ocorrências de cada termo (abordagem bag-of-words)."
      ],
      "metadata": {
        "id": "Gxw_ExbPU6K9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download do dataset"
      ],
      "metadata": {
        "id": "2FtZGrPKuTwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkWo-SJ3uUe-",
        "outputId": "a98fe8ed-b4f3-466c-96e7-b9fc180cdae1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_path = '/content/drive/MyDrive/Unicamp-aula-2/'\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(main_path):\n",
        "  os.makedirs(main_path)\n",
        "else:\n",
        "  print('Diretório já existente')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLcUasvzuXPB",
        "outputId": "2b9d4b63-f39d-45ef-95b4-4d33fa0a15d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diretório já existente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download de ferramentas auxiliares"
      ],
      "metadata": {
        "id": "-RLVOaq8TUJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyserini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be_swSbxurh7",
        "outputId": "7cdae8e0-c0f9-4e9f-8f97-01bfa16a41bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyserini\n",
            "  Downloading pyserini-0.20.0-py3-none-any.whl (137.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.1/137.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nmslib>=2.1.1\n",
            "  Downloading nmslib-2.1.1-cp38-cp38-manylinux2010_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.8.1\n",
            "  Downloading onnxruntime-1.14.1-cp38-cp38-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.22.4)\n",
            "Collecting lightgbm>=3.3.2\n",
            "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pyserini) (4.64.1)\n",
            "Requirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (3.4.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.10.1)\n",
            "Collecting sentencepiece>=0.1.95\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.8/dist-packages (from pyserini) (0.29.33)\n",
            "Collecting pandas>=1.4.0\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjnius>=1.4.0\n",
            "  Downloading pyjnius-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=4.6.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=3.3.2->pyserini) (0.38.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.1.21)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.19.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.4.0->pyserini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.4.0->pyserini) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.2.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (6.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (8.1.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.25.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.10.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.0.12)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.4.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (3.9.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.6.0->pyserini) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.26.14)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.2.1->pyserini) (8.1.3)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.2.1)\n",
            "Installing collected packages: tokenizers, sentencepiece, pyjnius, pybind11, humanfriendly, pandas, nmslib, huggingface-hub, coloredlogs, transformers, onnxruntime, lightgbm, pyserini\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed coloredlogs-15.0.1 huggingface-hub-0.12.1 humanfriendly-10.0 lightgbm-3.3.5 nmslib-2.1.1 onnxruntime-1.14.1 pandas-1.5.3 pybind11-2.6.1 pyjnius-1.4.2 pyserini-0.20.0 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/castorini/pyserini.git --recurse-submodules {main_path}/pyserini"
      ],
      "metadata": {
        "id": "O97kuBrZTyZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd {main_path}/pyserini/tools/eval && tar xvfz trec_eval.9.0.4.tar.gz && cd trec_eval.9.0.4 && make && cd ../../..\n",
        "!cd {main_path}/pyserini/tools/eval/ndeval && make && cd ../../.."
      ],
      "metadata": {
        "id": "OjR4FDswUJeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c163cc8-aecf-41bf-8b77-10543575bbc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trec_eval.9.0.4/\n",
            "trec_eval.9.0.4/m_prefs_pair.c\n",
            "trec_eval.9.0.4/m_ndcg_p.c\n",
            "trec_eval.9.0.4/m_infap.c\n",
            "trec_eval.9.0.4/m_num_q.c\n",
            "trec_eval.9.0.4/m_iprec_at_recall.c\n",
            "trec_eval.9.0.4/form_prefs_counts.c\n",
            "trec_eval.9.0.4/m_prefs_num_prefs_ful_ret.c\n",
            "trec_eval.9.0.4/utility_pool.c\n",
            "trec_eval.9.0.4/m_binG.c\n",
            "trec_eval.9.0.4/meas_avg.c\n",
            "trec_eval.9.0.4/m_gm_bpref.c\n",
            "trec_eval.9.0.4/m_runid.c\n",
            "trec_eval.9.0.4/m_bpref.c\n",
            "trec_eval.9.0.4/m_gm_map.c\n",
            "trec_eval.9.0.4/trec_eval.h\n",
            "trec_eval.9.0.4/m_yaap.c\n",
            "trec_eval.9.0.4/m_relstring.c\n",
            "trec_eval.9.0.4/m_Rprec.c\n",
            "trec_eval.9.0.4/m_prefs_avgjg.c\n",
            "trec_eval.9.0.4/m_success.c\n",
            "trec_eval.9.0.4/m_ndcg.c\n",
            "trec_eval.9.0.4/functions.h\n",
            "trec_eval.9.0.4/m_P_avgjg.c\n",
            "trec_eval.9.0.4/test/\n",
            "trec_eval.9.0.4/test/qrels.rel_level\n",
            "trec_eval.9.0.4/test/results.test\n",
            "trec_eval.9.0.4/test/qrels.test\n",
            "trec_eval.9.0.4/test/out.test.qrels_jg\n",
            "trec_eval.9.0.4/test/out.test.meas_params\n",
            "trec_eval.9.0.4/test/out.test.a\n",
            "trec_eval.9.0.4/test/out.test.prefs\n",
            "trec_eval.9.0.4/test/out.test.aqcM\n",
            "trec_eval.9.0.4/test/out.test.aql\n",
            "trec_eval.9.0.4/test/prefs.test\n",
            "trec_eval.9.0.4/test/out.test\n",
            "trec_eval.9.0.4/test/out.test.aq\n",
            "trec_eval.9.0.4/test/out.test.aqc\n",
            "trec_eval.9.0.4/test/out.test.qrels_prefs\n",
            "trec_eval.9.0.4/test/zscores_file\n",
            "trec_eval.9.0.4/test/qrels.123\n",
            "trec_eval.9.0.4/test/out.test.aqZ\n",
            "trec_eval.9.0.4/test/results.trunc\n",
            "trec_eval.9.0.4/test/prefs.results.test\n",
            "trec_eval.9.0.4/test/prefs.rank20\n",
            "trec_eval.9.0.4/m_11pt_avg.c\n",
            "trec_eval.9.0.4/m_G.c\n",
            "trec_eval.9.0.4/m_num_rel.c\n",
            "trec_eval.9.0.4/m_map_cut.c\n",
            "trec_eval.9.0.4/m_prefs_avgjg_ret.c\n",
            "trec_eval.9.0.4/m_Rprec_mult.c\n",
            "trec_eval.9.0.4/Makefile\n",
            "trec_eval.9.0.4/m_map_avgjg.c\n",
            "trec_eval.9.0.4/get_qrels_prefs.c\n",
            "trec_eval.9.0.4/README\n",
            "trec_eval.9.0.4/m_set_rel_P.c\n",
            "trec_eval.9.0.4/sysfunc.h\n",
            "trec_eval.9.0.4/m_prefs_pair_ret.c\n",
            "trec_eval.9.0.4/convert_zscores.c\n",
            "trec_eval.9.0.4/m_ndcg_cut.c\n",
            "trec_eval.9.0.4/m_prefs_pair_imp.c\n",
            "trec_eval.9.0.4/meas_print_single.c\n",
            "trec_eval.9.0.4/meas_print_final.c\n",
            "trec_eval.9.0.4/trec_eval.c\n",
            "trec_eval.9.0.4/m_num_ret.c\n",
            "trec_eval.9.0.4/get_prefs.c\n",
            "trec_eval.9.0.4/m_P.c\n",
            "trec_eval.9.0.4/get_qrels_jg.c\n",
            "trec_eval.9.0.4/m_rel_P.c\n",
            "trec_eval.9.0.4/meas_acc.c\n",
            "trec_eval.9.0.4/m_prefs_simp.c\n",
            "trec_eval.9.0.4/m_recall.c\n",
            "trec_eval.9.0.4/trec_format.h\n",
            "trec_eval.9.0.4/m_ndcg_rel.c\n",
            "trec_eval.9.0.4/m_num_nonrel_judged_ret.c\n",
            "trec_eval.9.0.4/formats.c\n",
            "trec_eval.9.0.4/bpref_bug\n",
            "trec_eval.9.0.4/README.windows.md\n",
            "trec_eval.9.0.4/m_prefs_num_prefs_ful.c\n",
            "trec_eval.9.0.4/m_set_map.c\n",
            "trec_eval.9.0.4/get_qrels.c\n",
            "trec_eval.9.0.4/m_set_F.c\n",
            "trec_eval.9.0.4/measures.c\n",
            "trec_eval.9.0.4/common.h\n",
            "trec_eval.9.0.4/meas_init.c\n",
            "trec_eval.9.0.4/m_recip_rank.c\n",
            "trec_eval.9.0.4/m_set_recall.c\n",
            "trec_eval.9.0.4/get_trec_results.c\n",
            "trec_eval.9.0.4/m_prefs_simp_ret.c\n",
            "trec_eval.9.0.4/m_num_rel_ret.c\n",
            "trec_eval.9.0.4/m_map.c\n",
            "trec_eval.9.0.4/m_utility.c\n",
            "trec_eval.9.0.4/form_res_rels.c\n",
            "trec_eval.9.0.4/form_res_rels_jg.c\n",
            "trec_eval.9.0.4/m_prefs_simp_imp.c\n",
            "trec_eval.9.0.4/m_prefs_num_prefs_poss.c\n",
            "trec_eval.9.0.4/m_prefs_avgjg_Rnonrel.c\n",
            "trec_eval.9.0.4/m_prefs_avgjg_Rnonrel_ret.c\n",
            "trec_eval.9.0.4/m_set_P.c\n",
            "trec_eval.9.0.4/m_prefs_avgjg_imp.c\n",
            "trec_eval.9.0.4/m_Rndcg.c\n",
            "trec_eval.9.0.4/CHANGELOG\n",
            "trec_eval.9.0.4/m_Rprec_mult_avgjg.c\n",
            "trec_eval.9.0.4/get_zscores.c\n",
            "make: 'trec_eval' is up to date.\n",
            "make: 'ndeval' is up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção do índice invertido"
      ],
      "metadata": {
        "id": "ZmvMxtynTmKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyserini.analysis import Analyzer, get_lucene_analyzer"
      ],
      "metadata": {
        "id": "cCpsvCE7u0o7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSMFneIku5L3",
        "outputId": "79d7e9ab-267f-44d3-ad67-5a2113929493"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer:Analyzer = Analyzer(get_lucene_analyzer(stemmer='porter'))\n",
        "\n",
        "def preprocess_and_tokenize(text):\n",
        "  return analyzer.analyze(text)"
      ],
      "metadata": {
        "id": "49JWfNjWu8ZJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "collection_path = main_path + '/collections/msmarco-passage/collection.tsv'\n",
        "\n"
      ],
      "metadata": {
        "id": "kwy8QAUCvBi1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "nltk.download('stopwords')  # Download stopwords if not already downloaded\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words = set(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhc11tGLJPWe",
        "outputId": "8136db68-03f3-460c-b18b-de0a8c63823f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import array\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "index_path = f\"{main_path}/index-tf-idf.pickle\"\n",
        "\n",
        "def load_or_build_inverted_index():\n",
        "  if os.path.exists(index_path):\n",
        "    with open(index_path, \"rb\") as f:\n",
        "      print(\"Loading index...\")\n",
        "      inverted_index = pickle.load(f)\n",
        "  else:\n",
        "    print(\"Building inverted index and vocabulary...\")\n",
        "    # set the chunk size\n",
        "    chunk_size = 1000\n",
        "    chunks = []\n",
        "    inverted_index = dict()\n",
        "    full_text = ''\n",
        "    vocab = set()\n",
        "\n",
        "    def process(row):\n",
        "      tokenized_text = preprocess_and_tokenize(row[1])\n",
        "      counter = Counter(tokenized_text)\n",
        "      doc_length = len(tokenized_text)\n",
        "      doc_id = row[0]\n",
        "      for token, count in counter.items():\n",
        "        if token not in stop_words:\n",
        "          #Para cada token, temos 2 arrays paralelos que armazenam os documentos e as frquências dos termos\n",
        "          inverted_index.setdefault(token, {\"docs\":array.array(\"L\", []), \"tf\":array.array(\"f\", [])})[\"docs\"].append(int(doc_id))\n",
        "          inverted_index.setdefault(token, {\"docs\":array.array(\"L\", []), \"tf\":array.array(\"f\", [])})[\"tf\"].append(count/doc_length)\n",
        "          vocab.add(token)\n",
        "\n",
        "    chunk_id = 0\n",
        "    n_documents = 0\n",
        "    len_vocab = len(vocab)\n",
        "\n",
        "    # iterate through the file in chunks\n",
        "    for chunk in pd.read_csv(collection_path, sep='\\t', header=None, chunksize=chunk_size):\n",
        "      # process the chunk here\n",
        "      if (chunk_id % 1000) == 0:\n",
        "        print(f'Processing chunk {chunk_id}')\n",
        "      for index, row in chunk.iterrows():\n",
        "        process(row)\n",
        "        n_documents += 1\n",
        "      del(chunk)\n",
        "      chunk_id += 1\n",
        "\n",
        "    index = {\"inverted_index\": inverted_index, \"vocab\": vocab, \n",
        "             \"n_documents\": n_documents}\n",
        "\n",
        "    with open(index_path, \"wb\") as f:\n",
        "      pickle.dump(index, f)\n",
        "\n",
        "  return index"
      ],
      "metadata": {
        "id": "O8GurqwF5yhX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = load_or_build_inverted_index()\n",
        "inverted_index = index[\"inverted_index\"]\n",
        "vocab = index[\"vocab\"]\n",
        "n_documents = index[\"n_documents\"]"
      ],
      "metadata": {
        "id": "N22tbji3zYev",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "1e02f186-f900-4cb9-a8c4-4cad7501a670"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building inverted index and vocabulary...\n",
            "Processing chunk 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-648188a8a708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_or_build_inverted_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minverted_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inverted_index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_documents\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-e7efc2271e44>\u001b[0m in \u001b[0;36mload_or_build_inverted_index\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Processing chunk {chunk_id}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mn_documents\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-e7efc2271e44>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0;31m#Para cada token, temos 2 arrays paralelos que armazenam os documentos e as frquências dos termos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0minverted_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"docs\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"docs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m           \u001b[0minverted_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"docs\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdoc_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m           \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_to_id = {token:(i+1) for i, token in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "FrcizXDWU8VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "i6tDR2B6VICh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(inverted_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD1BrbHRvMDL",
        "outputId": "6b33de11-7019-4bc7-86cc-208742394ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2660662"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPAQEOPipUuq",
        "outputId": "ac77f64d-0332-44fa-b0e1-2dcee6c11839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2660662"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {collection_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqUvI7BC5VHw",
        "outputId": "632abd79-f83b-4a78-a8b5-ab1dd313af5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\tThe presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.\n",
            "1\tThe Manhattan Project and its atomic bomb helped bring an end to World War II. Its legacy of peaceful uses of atomic energy continues to have an impact on history and science.\n",
            "2\tEssay on The Manhattan Project - The Manhattan Project The Manhattan Project was to see if making an atomic bomb possible. The success of this project would forever change the world forever making it known that something this powerful can be manmade.\n",
            "3\tThe Manhattan Project was the name for a project conducted during World War II, to develop the first atomic bomb. It refers specifically to the period of the project from 194 â¦ 2-1946 under the control of the U.S. Army Corps of Engineers, under the administration of General Leslie R. Groves.\n",
            "4\tversions of each volume as well as complementary websites. The first websiteâThe Manhattan Project: An Interactive Historyâis available on the Office of History and Heritage Resources website, http://www.cfo. doe.gov/me70/history. The Office of History and Heritage Resources and the National Nuclear Security\n",
            "5\tThe Manhattan Project. This once classified photograph features the first atomic bomb â a weapon that atomic scientists had nicknamed Gadget.. The nuclear age began on July 16, 1945, when it was detonated in the New Mexico desert.\n",
            "6\tNor will it attempt to substitute for the extraordinarily rich literature on the atomic bombs and the end of World War II. This collection does not attempt to document the origins and development of the Manhattan Project.\n",
            "7\tManhattan Project. The Manhattan Project was a research and development undertaking during World War II that produced the first nuclear weapons. It was led by the United States with the support of the United Kingdom and Canada. From 1942 to 1946, the project was under the direction of Major General Leslie Groves of the U.S. Army Corps of Engineers. Nuclear physicist Robert Oppenheimer was the director of the Los Alamos Laboratory that designed the actual bombs. The Army component of the project was designated the\n",
            "8\tIn June 1942, the United States Army Corps of Engineersbegan the Manhattan Project- The secret name for the 2 atomic bombs.\n",
            "9\tOne of the main reasons Hanford was selected as a site for the Manhattan Project's B Reactor was its proximity to the Columbia River, the largest river flowing into the Pacific Ocean from the North American coast.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação"
      ],
      "metadata": {
        "id": "K4t5V238T7d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics_file = main_path + '/pyserini/tools/topics-and-qrels/topics.dl20.txt'\n",
        "qrels_eval = main_path + '/pyserini/tools/topics-and-qrels/qrels.dl20-passage.txt'"
      ],
      "metadata": {
        "id": "aiujR-Y6KUtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head {topics_file}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F0hqvNoLta6",
        "outputId": "c9a5f010-e4dc-4896-b4c1-58ac7413f9dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1030303\twho is aziz hashim\r\n",
            "1037496\twho is rep scalise?\r\n",
            "1043135\twho killed nicholas ii of russia\r\n",
            "1045109\twho owns barnhart crane\r\n",
            "1049519\twho said no one can make you feel inferior\r\n",
            "1051399\twho sings monk theme song\r\n",
            "1056416\twho was the highest career passer  rating in the nfl\r\n",
            "1064670\twhy do hunters pattern their shotguns?\r\n",
            "1065636\twhy do some places on my scalp feel sore\r\n",
            "1071750\twhy is pete rose banned from hall of fame\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {qrels_eval}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ8H_jWOfBMs",
        "outputId": "551101d6-35c3-4ff2-be8e-84a7ebaf0edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23849 0 1020327 2\n",
            "23849 0 1034183 3\n",
            "23849 0 1120730 0\n",
            "23849 0 1139571 1\n",
            "23849 0 1143724 0\n",
            "23849 0 1147202 0\n",
            "23849 0 1150311 0\n",
            "23849 0 1158886 2\n",
            "23849 0 1175024 1\n",
            "23849 0 1201385 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def search(query):\n",
        "  doc_scores = defaultdict(int) # int (doc_id) -> int (score)\n",
        "  query_tokens = preprocess_and_tokenize(query)\n",
        "  print(query_tokens)\n",
        "  n_query_tokens = len(query_tokens)\n",
        "  query_tensor = torch.zeros(len(inverted_index), device=device)\n",
        "  doc_to_tensor = dict()\n",
        "  query_counter = Counter(query_tokens)\n",
        "\n",
        "  for token in query_tokens:\n",
        "    if token in inverted_index:\n",
        "      #Calcula TF-IDF para par (termo, query)\n",
        "      query_tf = query_counter[token]/n_query_tokens\n",
        "      doc_ids = inverted_index[token][\"docs\"]\n",
        "      n_docs_contain_term = len(set(doc_ids))\n",
        "      idf = math.log(n_documents / n_docs_contain_term)\n",
        "      query_tf_idf = query_tf * idf\n",
        "      query_tensor[token_to_id[token]] = query_tf_idf\n",
        "\n",
        "      for i, doc_id in enumerate(doc_ids):\n",
        "        if doc_id not in doc_scores: #para não processar um mesmo documento novamente\n",
        "          #Calcula TF-IDF para par (termo, documento)\n",
        "          doc_tf = inverted_index[token][\"tf\"][i]\n",
        "          doc_tf_idf = doc_tf * idf\n",
        "          doc_tensor = torch.zeros(len(inverted_index), device=device)\n",
        "          doc_tensor[token_to_id[token]] = doc_tf_idf\n",
        "          doc_to_tensor[doc_id] = doc_tensor    \n",
        "          \n",
        "  for doc_id, doc_tensor in doc_to_tensor.items():\n",
        "    doc_scores[doc_id] = F.cosine_similarity(query_tensor.unsqueeze(0), \n",
        "                                             doc_to_tensor[doc_id].unsqueeze(0), \n",
        "                                             dim=1).item()\n",
        "          \n",
        "  del(query_tensor)\n",
        "  del(doc_to_tensor)\n",
        "  return doc_scores"
      ],
      "metadata": {
        "id": "1VjKwZJMLvgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = search('who is aziz hashim')"
      ],
      "metadata": {
        "id": "yfHwaJWhNYBF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "b5b7b4ed-4d04-49ab-90ef-5f7f5f2ce26c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['who', 'aziz', 'hashim']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-1094eb379a9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'who is aziz hashim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-1515d246cbb1>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mn_query_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mquery_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverted_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mdoc_to_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mquery_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.75 GiB total capacity; 11.99 GiB already allocated; 8.81 MiB free; 14.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0nNth1oNnNe",
        "outputId": "6f4a6ca6-924e-463b-a28c-6d121e8669dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "245"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results\n",
        "#6989780, 1305521, 4358004, 1815707, 7508059"
      ],
      "metadata": {
        "id": "wualKpHjQOEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8f592c-2936-4de2-cb89-0ff96b73e09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {22484: 0.6599182486534119,\n",
              "             68532: 0.6599182486534119,\n",
              "             119291: 0.6599182486534119,\n",
              "             176182: 0.6599182486534119,\n",
              "             176183: 0.6599182486534119,\n",
              "             226464: 0.6599182486534119,\n",
              "             279227: 0.6599182486534119,\n",
              "             315873: 0.6599182486534119,\n",
              "             480287: 0.6599182486534119,\n",
              "             596813: 0.6599182486534119,\n",
              "             705402: 0.6599182486534119,\n",
              "             770274: 0.6599182486534119,\n",
              "             794624: 0.6599182486534119,\n",
              "             821997: 0.6599182486534119,\n",
              "             848943: 0.6599182486534119,\n",
              "             1038342: 0.6599182486534119,\n",
              "             1154757: 0.6599182486534119,\n",
              "             1161432: 0.6599182486534119,\n",
              "             1161439: 0.6599182486534119,\n",
              "             1358683: 0.6599182486534119,\n",
              "             1376556: 0.6599182486534119,\n",
              "             1376558: 0.6599182486534119,\n",
              "             1451842: 0.6599182486534119,\n",
              "             1451844: 0.6599182486534119,\n",
              "             1451845: 0.6599182486534119,\n",
              "             1451846: 0.6599182486534119,\n",
              "             1451847: 0.6599182486534119,\n",
              "             1451848: 0.6599182486534119,\n",
              "             1451849: 0.6599182486534119,\n",
              "             1451850: 0.6599182486534119,\n",
              "             1451851: 0.6599182486534119,\n",
              "             1513969: 0.6599182486534119,\n",
              "             1518706: 0.6599182486534119,\n",
              "             1546395: 0.6599182486534119,\n",
              "             1761460: 0.6599182486534119,\n",
              "             1815703: 0.6599182486534119,\n",
              "             1815707: 0.6599182486534119,\n",
              "             1905988: 0.6599182486534119,\n",
              "             2026758: 0.6599182486534119,\n",
              "             2047616: 0.6599182486534119,\n",
              "             2444312: 0.6599182486534119,\n",
              "             2484376: 0.6599182486534119,\n",
              "             2488127: 0.6599182486534119,\n",
              "             2563261: 0.6599182486534119,\n",
              "             2563265: 0.6599182486534119,\n",
              "             2563266: 0.6599182486534119,\n",
              "             2563267: 0.6599182486534119,\n",
              "             2563269: 0.6599182486534119,\n",
              "             2615250: 0.6599182486534119,\n",
              "             2620118: 0.6599182486534119,\n",
              "             2620119: 0.6599182486534119,\n",
              "             2699093: 0.6599182486534119,\n",
              "             2699097: 0.6599182486534119,\n",
              "             2755743: 0.6599182486534119,\n",
              "             2848596: 0.6599182486534119,\n",
              "             2937934: 0.6599182486534119,\n",
              "             2937935: 0.6599182486534119,\n",
              "             3062381: 0.6599182486534119,\n",
              "             3226332: 0.6599182486534119,\n",
              "             3226335: 0.6599182486534119,\n",
              "             3234722: 0.6599182486534119,\n",
              "             3234728: 0.6599182486534119,\n",
              "             3290826: 0.6599182486534119,\n",
              "             3302249: 0.6599182486534119,\n",
              "             3302250: 0.6599182486534119,\n",
              "             3302251: 0.6599182486534119,\n",
              "             3302252: 0.6599182486534119,\n",
              "             3302253: 0.6599182486534119,\n",
              "             3302254: 0.6599182486534119,\n",
              "             3302255: 0.6599182486534119,\n",
              "             3302256: 0.6599182486534119,\n",
              "             3302257: 0.6599182486534119,\n",
              "             3302258: 0.6599182486534119,\n",
              "             3327029: 0.6599182486534119,\n",
              "             3340457: 0.6599182486534119,\n",
              "             3734992: 0.6599182486534119,\n",
              "             3738183: 0.6599182486534119,\n",
              "             3744026: 0.6599182486534119,\n",
              "             3744030: 0.6599182486534119,\n",
              "             3765089: 0.6599182486534119,\n",
              "             3839846: 0.6599182486534119,\n",
              "             3853795: 0.6599182486534119,\n",
              "             3880502: 0.6599182486534119,\n",
              "             4148197: 0.6599182486534119,\n",
              "             4179453: 0.6599182486534119,\n",
              "             4228943: 0.6599182486534119,\n",
              "             4329618: 0.6599182486534119,\n",
              "             4363663: 0.6599182486534119,\n",
              "             4374265: 0.6599182486534119,\n",
              "             4488397: 0.6599182486534119,\n",
              "             4652515: 0.6599182486534119,\n",
              "             4658938: 0.6599182486534119,\n",
              "             4691526: 0.6599182486534119,\n",
              "             4696365: 0.6599182486534119,\n",
              "             4699939: 0.6599182486534119,\n",
              "             4820481: 0.6599182486534119,\n",
              "             4846462: 0.6599182486534119,\n",
              "             4898510: 0.6599182486534119,\n",
              "             4908784: 0.6599182486534119,\n",
              "             4930087: 0.6599182486534119,\n",
              "             4966548: 0.6599182486534119,\n",
              "             4966555: 0.6599182486534119,\n",
              "             5086539: 0.6599182486534119,\n",
              "             5103906: 0.6599182486534119,\n",
              "             5139079: 0.6599182486534119,\n",
              "             5212826: 0.6599182486534119,\n",
              "             5252010: 0.6599182486534119,\n",
              "             5256170: 0.6599182486534119,\n",
              "             5310898: 0.6599182486534119,\n",
              "             5391149: 0.6599182486534119,\n",
              "             5506223: 0.6599182486534119,\n",
              "             5533137: 0.6599182486534119,\n",
              "             5533139: 0.6599182486534119,\n",
              "             5533140: 0.6599182486534119,\n",
              "             5558703: 0.6599182486534119,\n",
              "             5657730: 0.6599182486534119,\n",
              "             5681379: 0.6599182486534119,\n",
              "             5681381: 0.6599182486534119,\n",
              "             5681383: 0.6599182486534119,\n",
              "             5681384: 0.6599182486534119,\n",
              "             5681385: 0.6599182486534119,\n",
              "             5681387: 0.6599182486534119,\n",
              "             5775795: 0.6599182486534119,\n",
              "             5824363: 0.6599182486534119,\n",
              "             5840551: 0.6599182486534119,\n",
              "             5885184: 0.6599182486534119,\n",
              "             5929352: 0.6599182486534119,\n",
              "             5936675: 0.6599182486534119,\n",
              "             5963129: 0.6599182486534119,\n",
              "             6039234: 0.6599182486534119,\n",
              "             6054026: 0.6599182486534119,\n",
              "             6054027: 0.6599182486534119,\n",
              "             6054029: 0.6599182486534119,\n",
              "             6054030: 0.6599182486534119,\n",
              "             6054032: 0.6599182486534119,\n",
              "             6054033: 0.6599182486534119,\n",
              "             6108837: 0.6599182486534119,\n",
              "             6224006: 0.6599182486534119,\n",
              "             6484356: 0.6599182486534119,\n",
              "             6683214: 0.6599182486534119,\n",
              "             6689899: 0.6599182486534119,\n",
              "             6764572: 0.6599182486534119,\n",
              "             6786344: 0.6599182486534119,\n",
              "             6887500: 0.6599182486534119,\n",
              "             6939422: 0.6599182486534119,\n",
              "             6939423: 0.6599182486534119,\n",
              "             6939426: 0.6599182486534119,\n",
              "             6939428: 0.6599182486534119,\n",
              "             6939430: 0.6599182486534119,\n",
              "             6939431: 0.6599182486534119,\n",
              "             6940380: 0.6599182486534119,\n",
              "             6942022: 0.6599182486534119,\n",
              "             6989780: 0.6599182486534119,\n",
              "             6991065: 0.6599182486534119,\n",
              "             7116093: 0.6599182486534119,\n",
              "             7156982: 0.751337468624115,\n",
              "             7168316: 0.6599182486534119,\n",
              "             7168317: 0.6599182486534119,\n",
              "             7168318: 0.6599182486534119,\n",
              "             7168320: 0.6599182486534119,\n",
              "             7168321: 0.6599182486534119,\n",
              "             7168323: 0.6599182486534119,\n",
              "             7168324: 0.6599182486534119,\n",
              "             7168325: 0.6599182486534119,\n",
              "             7183280: 0.6599182486534119,\n",
              "             7239999: 0.6599182486534119,\n",
              "             7240001: 0.6599182486534119,\n",
              "             7240005: 0.6599182486534119,\n",
              "             7284047: 0.6599182486534119,\n",
              "             7284048: 0.6599182486534119,\n",
              "             7284050: 0.6599182486534119,\n",
              "             7284052: 0.6599182486534119,\n",
              "             7284053: 0.6599182486534119,\n",
              "             7284055: 0.6599182486534119,\n",
              "             7645177: 0.6599182486534119,\n",
              "             7778036: 0.6599182486534119,\n",
              "             7970461: 0.6599182486534119,\n",
              "             7989095: 0.6599182486534119,\n",
              "             7989100: 0.6599182486534119,\n",
              "             7995154: 0.6599182486534119,\n",
              "             8153628: 0.6599182486534119,\n",
              "             8192997: 0.6599182486534119,\n",
              "             8219949: 0.6599182486534119,\n",
              "             8230659: 0.6599182486534119,\n",
              "             8351877: 0.6599182486534119,\n",
              "             8358916: 0.6599182486534119,\n",
              "             8403877: 0.6599182486534119,\n",
              "             8441139: 0.6599182486534119,\n",
              "             8542374: 0.6599182486534119,\n",
              "             8612121: 0.6599182486534119,\n",
              "             8649337: 0.6599182486534119,\n",
              "             8657424: 0.6599182486534119,\n",
              "             8657428: 0.6599182486534119,\n",
              "             8683568: 0.6599182486534119,\n",
              "             8710736: 0.6599182486534119,\n",
              "             8726429: 0.751337468624115,\n",
              "             8726430: 0.751337468624115,\n",
              "             8726433: 0.751337468624115,\n",
              "             8726434: 0.751337468624115,\n",
              "             8726435: 0.751337468624115,\n",
              "             8726436: 0.751337468624115,\n",
              "             8726437: 0.751337468624115,\n",
              "             8727420: 0.6599182486534119,\n",
              "             8754333: 0.6599182486534119,\n",
              "             8793631: 0.6599182486534119,\n",
              "             8828432: 0.6599182486534119,\n",
              "             309441: 0.751337468624115,\n",
              "             336399: 0.751337468624115,\n",
              "             1292819: 0.751337468624115,\n",
              "             1292821: 0.751337468624115,\n",
              "             1292822: 0.751337468624115,\n",
              "             1292823: 0.751337468624115,\n",
              "             1305519: 0.751337468624115,\n",
              "             1305520: 0.751337468624115,\n",
              "             1305521: 0.751337468624115,\n",
              "             1305528: 0.751337468624115,\n",
              "             1492373: 0.751337468624115,\n",
              "             2001450: 0.751337468624115,\n",
              "             2597060: 0.751337468624115,\n",
              "             2597061: 0.751337468624115,\n",
              "             2597066: 0.751337468624115,\n",
              "             2782702: 0.751337468624115,\n",
              "             3185530: 0.751337468624115,\n",
              "             3784253: 0.751337468624115,\n",
              "             4130105: 0.751337468624115,\n",
              "             4358001: 0.751337468624115,\n",
              "             4358004: 0.751337468624115,\n",
              "             4567726: 0.751337468624115,\n",
              "             4760232: 0.751337468624115,\n",
              "             4882562: 0.751337468624115,\n",
              "             5120735: 0.751337468624115,\n",
              "             5156631: 0.751337468624115,\n",
              "             5285789: 0.751337468624115,\n",
              "             6222298: 0.751337468624115,\n",
              "             6271629: 0.751337468624115,\n",
              "             6696177: 0.751337468624115,\n",
              "             7259969: 0.751337468624115,\n",
              "             7508058: 0.751337468624115,\n",
              "             7508059: 0.751337468624115,\n",
              "             7616221: 0.751337468624115,\n",
              "             7616223: 0.751337468624115,\n",
              "             7875818: 0.751337468624115,\n",
              "             8126314: 0.751337468624115,\n",
              "             8726432: 0.751337468624115,\n",
              "             8777713: 0.751337468624115})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OBS.: A lista de stopwords do Lucene Analyzer parece ser muito retrista.  Assim, para reduzir o tamanho do índice, uma alternativa seria combinar com a lista de stopwords do NLTK - ou seja, só salvar no índie invertido se não estiver na lsita de stopwords do NLTK."
      ],
      "metadata": {
        "id": "bXuqO206Q_Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_document_by_id(id):\n",
        "  result = None\n",
        "  with open(collection_path, 'r') as f:\n",
        "    for line in f:\n",
        "      fields = line.strip().split('\\t')\n",
        "      doc_id = fields[0]\n",
        "      if doc_id == id:\n",
        "        result = fields[1]\n",
        "        break\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "eExn_oy6Wh3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)[:10]"
      ],
      "metadata": {
        "id": "A0O3yBIEYXDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-udZL3mbY32L",
        "outputId": "7a440738-6b06-4af1-ada3-10791e6ab067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(7156982, tensor([0.7513], device='cuda:0')),\n",
              " (8726429, tensor([0.7513], device='cuda:0')),\n",
              " (8726430, tensor([0.7513], device='cuda:0')),\n",
              " (8726433, tensor([0.7513], device='cuda:0')),\n",
              " (8726434, tensor([0.7513], device='cuda:0')),\n",
              " (8726435, tensor([0.7513], device='cuda:0')),\n",
              " (8726436, tensor([0.7513], device='cuda:0')),\n",
              " (8726437, tensor([0.7513], device='cuda:0')),\n",
              " (309441, tensor([0.7513], device='cuda:0')),\n",
              " (336399, tensor([0.7513], device='cuda:0'))]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_document_by_id('336399')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "xnUN599MY5XY",
        "outputId": "cc110284-11fc-423b-941c-a0f450bdc946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Amla may refer to: 1  Indian gooseberry, called amla in Hindi. 2  Hashim Amla, a South African cricketer of Indian descent. 3  Ahmed Amla, a South African cricketer and brother of Hashim.mla may refer to: 1  Indian gooseberry, called amla in Hindi. 2  Hashim Amla, a South African cricketer of Indian descent. 3  Ahmed Amla, a South African cricketer and brother of Hashim.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_to_results = dict()\n",
        "\n",
        "with open(topics_file, 'r') as f:\n",
        "  for line in f:\n",
        "      fields = line.strip().split('\\t')\n",
        "      query_id = fields[0]\n",
        "      query_text = fields[1]\n",
        "      results = search(query_text)\n",
        "      query_to_results[int(query_id)] = sorted(results.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "with open('run.dl20.boolean.trec', 'w') as f:\n",
        "  for query_id, results in query_to_results.items():\n",
        "    for i, (doc_id, score) in enumerate(results):\n",
        "      f.write(f'{query_id}\\tQ0\\t{doc_id}\\t{i+1}\\t{score}\\tboolean\\n')"
      ],
      "metadata": {
        "id": "cLL1cRNcZAt2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "6a6843ad-5a26-429c-e497-552c61b9f1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['who', 'aziz', 'hashim']\n",
            "['who', 'rep', 'scalis']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-a2694b05c148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mquery_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mquery_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mquery_to_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-de1b949478aa>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0mdoc_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minverted_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m           \u001b[0mdoc_tf_idf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_tf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m           \u001b[0mdoc_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverted_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m           \u001b[0mdoc_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_tf_idf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0mdoc_to_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.75 GiB total capacity; 11.99 GiB already allocated; 8.81 MiB free; 14.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head run.dl20.boolean.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiRHnKrlFPyw",
        "outputId": "58c9a370-cfba-411c-a68e-016914b31c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1030303\tQ0\t7156982\t1\t2\tboolean\n",
            "1030303\tQ0\t8726429\t2\t2\tboolean\n",
            "1030303\tQ0\t8726430\t3\t2\tboolean\n",
            "1030303\tQ0\t8726433\t4\t2\tboolean\n",
            "1030303\tQ0\t8726434\t5\t2\tboolean\n",
            "1030303\tQ0\t8726435\t6\t2\tboolean\n",
            "1030303\tQ0\t8726436\t7\t2\tboolean\n",
            "1030303\tQ0\t8726437\t8\t2\tboolean\n",
            "1030303\tQ0\t794624\t9\t1\tboolean\n",
            "1030303\tQ0\t4820481\t10\t1\tboolean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python {main_path}/pyserini/tools/scripts/msmarco/convert_msmarco_to_trec_qrels.py \\\n",
        "   --input {qrels_eval} \\\n",
        "   --output qrels.dl20.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u51xHcmNGJ2i",
        "outputId": "ebf21590-fa8a-4f98-b028-79f54b296911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head qrels.dl20.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtocDxsYHZDV",
        "outputId": "1edd2682-205e-4b39-d31a-dc82610ca623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23849 0 1020327 2\n",
            "23849 0 1034183 3\n",
            "23849 0 1120730 0\n",
            "23849 0 1139571 1\n",
            "23849 0 1143724 0\n",
            "23849 0 1147202 0\n",
            "23849 0 1150311 0\n",
            "23849 0 1158886 2\n",
            "23849 0 1175024 1\n",
            "23849 0 1201385 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 755 {main_path}/pyserini/tools/eval/trec_eval.9.0.4/trec_eval"
      ],
      "metadata": {
        "id": "4fNz7EIP_ua0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{main_path}/pyserini/tools/eval/trec_eval.9.0.4/trec_eval -c -m map -m ndcg_cut.10 -l 2 \\\n",
        "   qrels.dl20.trec run.dl20.boolean.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMNRIGZZHpu6",
        "outputId": "cf06c9f6-501c-42a1-eee0-253c42f11f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "map                   \tall\t0.1117\n",
            "ndcg_cut_10           \tall\t0.3189\n"
          ]
        }
      ]
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl6AY1Y8ju26"
      },
      "source": [
        "# InPars - Finetuning\n",
        "\n",
        "Author: Monique Monteiro (moniquelouise@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXF3o5yEkNSt",
        "outputId": "b9e0aaad-ac64-4192-8bce-9313a723c214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "-v3hb4m4kiMN"
      },
      "outputs": [],
      "source": [
        "main_dir = \"/content/gdrive/MyDrive/Unicamp-aula-9\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VbgW72ck840"
      },
      "source": [
        "## Libraries installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "H9fNF08Mk-Qj"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "OzXI3csdl3LL"
      },
      "outputs": [],
      "source": [
        "!pip install jsonlines -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Q_usvh8ar_7u"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "qO7NycuisFP-"
      },
      "outputs": [],
      "source": [
        "!pip install trectools -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "3O9_kDhglWnj"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from statistics import mean, stdev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LREHGdcylcQ5"
      },
      "source": [
        "Random seeds definition, to enable replication of results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_GMvpOilnZV",
        "outputId": "d3b254c3-6b9d-4ac8-9b4c-cbcea92c4fa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc6781dcef0>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztPD7AVOmRmq"
      },
      "source": [
        "## Dataset processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Y7clZNOYphKw"
      },
      "outputs": [],
      "source": [
        "import jsonlines\n",
        "\n",
        "id_to_text = dict()\n",
        "\n",
        "with jsonlines.open(f\"{main_dir}/trec-covid/corpus.jsonl\") as reader:\n",
        "  for item in reader:\n",
        "    id = item[\"_id\"]\n",
        "    text = item[\"title\"] + ' ' + item[\"text\"]\n",
        "    id_to_text[id] = text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_training_data(dataset_file, model_name):\n",
        "  dataset = []\n",
        "  dataset_ids = []\n",
        "  i = 0\n",
        "\n",
        "  with open(dataset_file, 'r') as f:\n",
        "    for line in f:\n",
        "      data = json.loads(line)\n",
        "      query = data[\"query\"]\n",
        "      positive_doc_id = data[\"positive_doc_id\"]\n",
        "      negative_doc_ids = data[\"negative_doc_ids\"]\n",
        "      \n",
        "      #Chooses a random negative document\n",
        "      negative_doc_id = random.choice(negative_doc_ids)\n",
        "\n",
        "      #Gets the documents texts\n",
        "      positive_doc = id_to_text[positive_doc_id]\n",
        "      negative_doc = id_to_text[negative_doc_id]\n",
        "\n",
        "      dataset.append((query, positive_doc, negative_doc))\n",
        "      dataset_ids.append((i, positive_doc_id, negative_doc_id))\n",
        "\n",
        "      i+=1\n",
        "\n",
        "  df = pd.DataFrame(dataset, columns=['query', 'pos', 'neg'])\n",
        "\n",
        "  df_pos = pd.DataFrame()\n",
        "  df_neg = pd.DataFrame()\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if model_name == 'microsoft/MiniLM-L12-H384-uncased':\n",
        "      df_pos = df_pos.append({\"query\":row[0], \"passage\":row[1], \"score\":1.0}, \n",
        "                             ignore_index=True)\n",
        "      df_neg = df_neg.append({\"query\":row[0], \"passage\":row[2], \"score\":0.0}, \n",
        "                             ignore_index=True)\n",
        "    elif model_name == 'cross-encoder/ms-marco-MiniLM-L-6-v2':\n",
        "      df_pos = df_pos.append({\"query\":row[0], \"passage\":row[1], \"score\":True}, \n",
        "                             ignore_index=True)\n",
        "      df_neg = df_neg.append({\"query\":row[0], \"passage\":row[2], \"score\":False}, \n",
        "                             ignore_index=True)\n",
        "\n",
        "  print(model_name)\n",
        "  print(df_pos.head())\n",
        "  X_train_pos = df_pos.drop(\"score\", axis=1)\n",
        "  Y_train_pos = df_pos[\"score\"]\n",
        "\n",
        "  X_train_pos, X_val_pos, Y_train_pos, Y_val_pos = train_test_split(X_train_pos, \n",
        "                                                                    Y_train_pos, \n",
        "                                                                    test_size=0.1, \n",
        "                                                                    random_state=42)\n",
        "\n",
        "  X_train_neg = df_neg.drop(\"score\", axis=1)\n",
        "  Y_train_neg = df_neg[\"score\"]\n",
        "\n",
        "  X_train_neg, X_val_neg, Y_train_neg, Y_val_neg = train_test_split(X_train_neg, \n",
        "                                                                    Y_train_neg, \n",
        "                                                                    test_size=0.1, \n",
        "                                                                    random_state=42)\n",
        "\n",
        "  X_train = pd.concat([X_train_pos, X_train_neg], axis=0, ignore_index=True)\n",
        "  Y_train = pd.concat([Y_train_pos, Y_train_neg], axis=0, ignore_index=True)\n",
        "  X_val = pd.concat([X_val_pos, X_val_neg], axis=0, ignore_index=True)\n",
        "  Y_val = pd.concat([Y_val_pos, Y_val_neg], axis=0, ignore_index=True)\n",
        "\n",
        "  return X_train, Y_train, X_val, Y_val\n"
      ],
      "metadata": {
        "id": "0iMV55JsYTbq"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA4uHLHi4PS8"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "JIBv9POV13Cg"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm \n",
        "\n",
        "def evaluate(model, dataloader, set_name, model_name):\n",
        "    losses = []\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, mininterval=0.5, desc=set_name, disable=False):\n",
        "            outputs = model(**batch.to(device))\n",
        "            loss_val = outputs.loss\n",
        "            losses.append(loss_val.cpu().item())\n",
        "            preds = outputs.logits.argmax(dim=1)\n",
        "            \n",
        "            if model_name == 'cross-encoder/ms-marco-MiniLM-L-6-v2':\n",
        "              preds  = (outputs.logits.view(-1)>0).float()\n",
        "            \n",
        "            correct += (preds == batch['labels']).sum().item()\n",
        "\n",
        "    print(f'{set_name} loss: {mean(losses):0.3f}; {set_name} accuracy: {correct / len(dataloader.dataset):0.3f}')\n",
        "    return correct / len(dataloader.dataset)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "sqMbMf2TBuRc"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch import optim\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "HPtqFbM9B0Ws"
      },
      "outputs": [],
      "source": [
        "from transformers.optimization import get_constant_schedule\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def train(model_name, epochs = 5, lr=5e-5):\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
        "  print('Parameters', model.num_parameters())\n",
        "\n",
        "  optimizer = optim.AdamW(model.parameters(), lr)\n",
        "  num_training_steps = epochs * len(dataloader_train)\n",
        "\n",
        "  num_warmup_steps = int(num_training_steps * 0.1)\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, \n",
        "                                              num_training_steps)\n",
        "  #scheduler = get_constant_schedule(optimizer)\n",
        "\n",
        "  evaluate(model=model, dataloader=dataloader_valid, set_name='Valid', \n",
        "           model_name=model_name)\n",
        "  best_acc = 0\n",
        "\n",
        "  # Training loop\n",
        "  for epoch in tqdm(range(epochs), desc='Epochs'):\n",
        "      model.train()\n",
        "      train_losses = []\n",
        "      for batch in tqdm(dataloader_train, mininterval=0.5, desc='Train', \n",
        "                        disable=False):\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(**batch.to(device))\n",
        "          loss = outputs.loss\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "          train_losses.append(loss.cpu().item())\n",
        "\n",
        "      print(f'Epoch: {epoch + 1} Training loss: {mean(train_losses):0.2f}')\n",
        "      acc = evaluate(model=model, dataloader=dataloader_valid, set_name='Valid', \n",
        "                     model_name=model_name)\n",
        "      #Saves the best checkpoint\n",
        "      if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        if os.path.exists(f'{MODELS_PATH}/best_checkpoint'):\n",
        "          shutil.rmtree(f'{MODELS_PATH}/best_checkpoint')\n",
        "        model.save_pretrained(f'{MODELS_PATH}/best_checkpoint')\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "dUyclIExB5Xz"
      },
      "outputs": [],
      "source": [
        "MODELS_PATH = '/content/gdrive/MyDrive/Unicamp-aula-9'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKhEqfhxmSrE"
      },
      "source": [
        "### Reranking\n",
        "\n",
        "Evaluation on TREC-COVID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "1jQ4GA94odiq"
      },
      "outputs": [],
      "source": [
        "id_to_query = dict()\n",
        "\n",
        "with jsonlines.open(f\"{main_dir}/trec-covid/queries.jsonl\") as reader:\n",
        "  for item in reader:\n",
        "    id = item[\"_id\"]\n",
        "    text = item[\"text\"]\n",
        "    id_to_query[id] = text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "YmsEEs8Fo4EE"
      },
      "outputs": [],
      "source": [
        "import jsonlines\n",
        "\n",
        "id_to_doc = dict()\n",
        "\n",
        "with jsonlines.open(f\"{main_dir}/trec-covid/corpus.jsonl\") as reader:\n",
        "  for item in reader:\n",
        "    id = item[\"_id\"]\n",
        "    text = item[\"title\"] + ' ' + item[\"text\"]\n",
        "    id_to_doc[id] = text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzDoT-w4qPPC",
        "outputId": "c127118c-6b68-45bb-bd8b-77ac77ed8d98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Q0 dv9m19yk 1 4.158100 Anserini\n",
            "1 Q0 kgifmjvb 2 3.338900 Anserini\n",
            "1 Q0 wmfcey6f 3 3.338899 Anserini\n",
            "1 Q0 safr9z37 4 3.220100 Anserini\n",
            "1 Q0 0paafp5j 5 3.207300 Anserini\n",
            "1 Q0 96zsd27n 6 3.207299 Anserini\n",
            "1 Q0 4dtk1kyh 7 3.184800 Anserini\n",
            "1 Q0 lhd0jn0z 8 2.903200 Anserini\n",
            "1 Q0 55dihml5 9 2.899800 Anserini\n",
            "1 Q0 qtx0d5f8 10 2.888800 Anserini\n"
          ]
        }
      ],
      "source": [
        "!head {main_dir}/trec-covid/run.trec-covid.bm25tuned.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "RxWAzUWWSwfK"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "def tokenize_test_queries_and_passages():\n",
        "  tokenized_queries = None\n",
        "  tokenized_passages = None\n",
        "\n",
        "  if os.path.exists(f\"{main_dir}/trec-covid/tok_queries_test.pickle\"):\n",
        "    with open(f\"{main_dir}/trec-covid/tok_queries_test.pickle\", \"rb\") as f:\n",
        "      print(\"Loading test queries...\")\n",
        "      tokenized_queries = pickle.load(f) \n",
        "\n",
        "  if os.path.exists(f\"{main_dir}/trec-covid/tok_passages_test.pickle\"):\n",
        "    with open(f\"{main_dir}/trec-covid/tok_passages_test.pickle\", \"rb\") as f:\n",
        "      print(\"Loading test passages...\")\n",
        "      tokenized_passages = pickle.load(f) \n",
        "\n",
        "  query_ids = []\n",
        "  queries = []\n",
        "  passage_ids = []\n",
        "  passages = []\n",
        "\n",
        "  with open(f'{main_dir}/trec-covid/run.trec-covid.bm25tuned.txt') as f:\n",
        "    for line in f:\n",
        "        fields = line.strip().split()\n",
        "        query_id = fields[0]\n",
        "        query_ids.append(query_id)\n",
        "        passage_id = fields[2]\n",
        "        passage_ids.append(passage_id)\n",
        "        \n",
        "        if not tokenized_queries:\n",
        "          query_text = id_to_query[query_id]\n",
        "          queries.append(query_text)\n",
        "\n",
        "        if not tokenized_passages:\n",
        "          passage_text = id_to_doc[passage_id]\n",
        "          passages.append(passage_text)\n",
        "\n",
        "  if not tokenized_queries:\n",
        "    tokenized_queries = tokenizer(queries, max_length=max_length_query, truncation=True)\n",
        "\n",
        "    with open(f\"{main_dir}/trec-covid/tok_queries_test.pickle\", 'wb') as f:\n",
        "      pickle.dump(tokenized_queries, f)\n",
        "\n",
        "  if not tokenized_passages:\n",
        "    tokenized_passages = tokenizer(passages, max_length=max_length_passage, truncation=True)\n",
        "\n",
        "    with open(f\"{main_dir}/trec-covid/tok_passages_test.pickle\", 'wb') as f:\n",
        "      pickle.dump(tokenized_passages, f)\n",
        "\n",
        "  return tokenized_queries, tokenized_passages, query_ids, passage_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ICYO-sk2q97w"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_test_dataset(model, dataloader, set_name, use_logits=False):\n",
        "    scores = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, mininterval=0.5, desc=set_name, disable=False):\n",
        "            outputs = model(**batch.to(device))\n",
        "            if use_logits:\n",
        "              # Usa os logits brutos\n",
        "              pos_score = outputs.logits[:,1]\n",
        "            else:\n",
        "              # Usa os logits normalizados pelo softmax (por default)\n",
        "              pos_score = torch.softmax(outputs.logits,1)[:,1]\n",
        "            scores = scores + pos_score.tolist()\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "euEsi3enrB1G"
      },
      "outputs": [],
      "source": [
        "def evaluate_ndcg_10(scores, model_name, eval_desc, query_ids, passage_ids):\n",
        "  zipped_results = []\n",
        "\n",
        "  #Por alguma razão misteriosa, o zip do Python não funcionou, deixou a lista \n",
        "  #vazia ou impossível de ser iterada.\n",
        "  for i, query_id in enumerate(query_ids):\n",
        "    zipped_results.append((query_id, passage_ids[i], scores[i]))\n",
        "\n",
        "  #Quebra a lista em sublistas por query\n",
        "  prev_query_id = -1\n",
        "  sublists = []\n",
        "  current_list = []\n",
        "\n",
        "  for query_id, passage_id, score in zipped_results:\n",
        "    if query_id != prev_query_id:\n",
        "      if len(current_list) > 0:\n",
        "        sublists.append(current_list)\n",
        "        current_list = []\n",
        "    current_list.append((query_id, passage_id, score))\n",
        "    prev_query_id = query_id\n",
        "\n",
        "  if len(current_list) > 0:\n",
        "    sublists.append(current_list)\n",
        "\n",
        "  # Ordena cada sublista\n",
        "  sorted_list = []\n",
        "\n",
        "  for sublist in sublists:\n",
        "    sorted_sublist = sorted(sublist, key=lambda x: x[2], reverse=True)\n",
        "    sorted_list += sorted_sublist\n",
        "\n",
        "  # Gera o arquivo de run no formato TREC\n",
        "  trec_run_file = f\"{main_dir}/trec-covid/run.trec-covid.bert_reranked_{model_name.replace('/', '_')}_{eval_desc}.trec\"\n",
        "  with open(trec_run_file, \"w\") as f:\n",
        "    for i, (query_id, passage_id, score) in enumerate(sorted_list):\n",
        "      f.write(f'{query_id}\\t{passage_id}\\t{i+1}\\t{score}\\tbert_reranked_{model_name}\\n')\n",
        "\n",
        "  return trec_run_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "jiCxYlhmrpy6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "qrel = pd.read_csv(f\"{main_dir}/trec-covid/test.tsv\", sep=\"\\t\", header=None, \n",
        "                   skiprows=1, names=[\"query\", \"docid\", \"rel\"])\n",
        "qrel[\"q0\"] = \"q0\"\n",
        "qrel = qrel.to_dict(orient=\"list\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrO6OnGHOAZD",
        "outputId": "6acea97d-9e3c-46c4-b9bf-c47aa7395346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query-id\tcorpus-id\tscore\r\n",
            "1\t005b2j4b\t2\r\n",
            "1\t00fmeepz\t1\r\n",
            "1\tg7dhmyyo\t2\r\n",
            "1\t0194oljo\t1\r\n",
            "1\t021q9884\t1\r\n",
            "1\t02f0opkr\t1\r\n",
            "1\t047xpt2c\t0\r\n",
            "1\t04ftw7k9\t0\r\n",
            "1\tpl9ht0d0\t0\r\n"
          ]
        }
      ],
      "source": [
        "!head {main_dir}/trec-covid/test.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "MiOlDyPLsOWD"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "\n",
        "def eval_ndcg10(run):\n",
        "  trec_eval = load(\"trec_eval\")\n",
        "  results = trec_eval.compute(predictions=[run], references=[qrel])\n",
        "  return results['NDCG@10'] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CzDcRGgaUUW"
      },
      "source": [
        "## Finetuning with cross-encoder/ms-marco-MiniLM-L-6-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "IjMVqQeua7s6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils import data\n",
        "from transformers import BatchEncoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "OgTbpfKJs_7f"
      },
      "outputs": [],
      "source": [
        "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "WF7UWPZTa5EJ"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "0qfTHS-gaC7U"
      },
      "outputs": [],
      "source": [
        "class MSMARCODataset(data.Dataset):\n",
        "    def __init__(self, tokenizer, query, passages, targets, max_lenght=356, \n",
        "                 return_token_type_ids=False):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.query = query\n",
        "        self.passages = passages\n",
        "        self.targets = targets\n",
        "        self.max_lenght = max_lenght\n",
        "        self.return_token_type_ids = return_token_type_ids\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.query)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        instruction_token = self.tokenizer(self.query[idx],self.passages[idx],\n",
        "                                           max_length=self.max_lenght, \n",
        "                                           truncation=True,\n",
        "                                           padding=\"max_length\", \n",
        "                                           return_tensors='pt',\n",
        "                                           return_token_type_ids=self.return_token_type_ids)\n",
        "\n",
        "\n",
        "        #token_type_ids\n",
        "        if self.return_token_type_ids:\n",
        "          return {'input_ids':torch.squeeze(instruction_token['input_ids']).long().to(device),\\\n",
        "                  'token_type_ids': torch.squeeze(instruction_token['token_type_ids']).long().to(device),\\\n",
        "                  'attention_mask':torch.squeeze(instruction_token['attention_mask']).long().to(device), \\\n",
        "                  'labels':torch.tensor(self.targets[idx], dtype=torch.float16)}\n",
        "        else:\n",
        "          return {'input_ids':torch.squeeze(instruction_token['input_ids']).long().to(device),\\\n",
        "                  'attention_mask':torch.squeeze(instruction_token['attention_mask']).long().to(device), \\\n",
        "                  'labels':torch.tensor(self.targets[idx], dtype=torch.float16)}\n",
        "              \n",
        "def collate_fn(batch):\n",
        "    return BatchEncoding(tokenizer.pad(batch, return_tensors='pt'))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "4gju5x63c7YH"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "query_ids = []\n",
        "queries = []\n",
        "passage_ids = []\n",
        "passages = []\n",
        "\n",
        "with open(f'{main_dir}/trec-covid/run.trec-covid.bm25tuned.txt') as f:\n",
        "  for line in f:\n",
        "      fields = line.strip().split()\n",
        "      query_id = fields[0]\n",
        "      query_ids.append(query_id)\n",
        "      passage_id = fields[2]\n",
        "      passage_ids.append(passage_id)\n",
        "\n",
        "      query_text = id_to_query[query_id]\n",
        "      queries.append(query_text)\n",
        "\n",
        "      passage_text = id_to_doc[passage_id]\n",
        "      passages.append(passage_text)\n"
      ],
      "metadata": {
        "id": "HWAEJKL2Kz6E"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = MSMARCODataset(tokenizer, queries, passages, [1]*len(queries), return_token_type_ids=True)"
      ],
      "metadata": {
        "id": "sp4QwMbYLjkg"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_test = data.DataLoader(dataset_test, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "KZj-ULtELy6j"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_test_dataset2(model, dataloader, set_name):\n",
        "  scores = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(dataloader, mininterval=0.5, desc=set_name, disable=False):\n",
        "      outputs = model(**batch.to(device))\n",
        "      # Usa os logits brutos\n",
        "      pos_score = outputs.logits[:,0]\n",
        "      scores = scores + pos_score.tolist()\n",
        "  return scores"
      ],
      "metadata": {
        "id": "LRdDegBDNY8E"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning with more datasets"
      ],
      "metadata": {
        "id": "S0fHZGHXU7L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "\n",
        "# Set the path of the directory containing JSONL files\n",
        "directory_path = f\"{main_dir}/trec-covid/datasets/\"\n",
        "print(directory_path)\n",
        "\n",
        "# Define an empty list to store the concatenated data\n",
        "data = []\n",
        "\n",
        "# Loop through all the JSONL files in the directory\n",
        "for filename in glob.glob(directory_path + \"*.jsonl\"):\n",
        "  print(filename)\n",
        "  with open(filename, \"r\") as file:\n",
        "      # Read each line in the file and append to the data list\n",
        "      for line in file:\n",
        "          data.append(json.loads(line))\n",
        "\n",
        "# Write the concatenated data to a new JSONL file\n",
        "with open(\"concatenated.jsonl\", \"w\") as outfile:\n",
        "    for item in data:\n",
        "        # Write each item as a JSON object on a separate line\n",
        "        outfile.write(json.dumps(item) + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EewSFUOwU9jH",
        "outputId": "3abd73d9-bb3a-4744-c01b-04105f001720"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/monique_monteiro_1000_queries.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/eduseiti_100_queries_expansion_20230501_01.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/gustavo_1k_cohere.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/hugo_padovani_query_generation.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/juliatessler_1000_queries.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/leandro_carisio_01.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/leonardo_avila_queries_v1.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/leonardo_pacheco_1k_generated_queries_20230502.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/manoel_1k_generated_queries_20230430.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/manoel_2k_generated_queries_20230501.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/marcospiau_1k_v1.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/marcus_borela_1k_gptj6b_20230501.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/marcus_borela_1k_gptj6b_20230501_v2.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/mirelle_1k_generated_queries_20230501.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/pedro_holanda_1k_generated_queries_20230502.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/pedrogengo_queries_inparsv1.jsonl\n",
            "/content/gdrive/MyDrive/Unicamp-aula-9/trec-covid/datasets/thiago_laitz_1k_queries.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head concatenated.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQtEJCBcbrJ6",
        "outputId": "d943d86c-6eda-4def-9228-c62fa04bd1b5"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"query\": \"What is the most suitable protein for a diagnostic approach for Salmonella Enteritidis and why?\", \"positive_doc_id\": \"m1cmkkw3\", \"negative_doc_ids\": [\"0o3mryu1\", \"qpq7i1ya\", \"j5mkparg\", \"auoo0dm5\", \"dqfvrerw\"]}\n",
            "{\"query\": \"What is Cryptosporidium parvum and why is it a major cause of disease in both humans and animals?\", \"positive_doc_id\": \"ukbl0svm\", \"negative_doc_ids\": [\"k3u2nvpe\", \"gc11fyms\", \"xoq9qblv\", \"20o4ufa3\", \"3huo5nf0\"]}\n",
            "{\"query\": \"What is the role of the renin-angiotensin-aldosterone system in the context of SARS-CoV-2 infection?\", \"positive_doc_id\": \"12o4zey2\", \"negative_doc_ids\": [\"6gd6nwpu\", \"dt4t2wos\", \"8zwfkken\", \"sv7xpi4f\", \"6pf73z08\"]}\n",
            "{\"query\": \"What are the functions of individual endolysosomal proteases in cellular processes such as autophagy and lipoprotein particle degradation?\", \"positive_doc_id\": \"eqv6a7tj\", \"negative_doc_ids\": [\"gmrty2uu\", \"uzn214j6\", \"032utjfh\", \"efet3ozc\", \"0muwl6oc\"]}\n",
            "{\"query\": \"What is the prevalence of olfactory dysfunction in SARS-CoV-2 patients?\", \"positive_doc_id\": \"66gu5af1\", \"negative_doc_ids\": [\"o6atz33c\", \"nm2bq717\", \"9hvhru6o\", \"381esemd\", \"exvvms1j\"]}\n",
            "{\"query\": \"What are the main differences between cultures of sarcoid origin and controls in terms of cytokine concentration?\", \"positive_doc_id\": \"10j46r1a\", \"negative_doc_ids\": [\"gnzau8uj\", \"mmafv2b5\", \"dckuhrlf\", \"3tkx57g1\", \"m38jah1z\"]}\n",
            "{\"query\": \"What animal model was used to study Middle East Respiratory Syndrome Coronavirus in the laboratory?\", \"positive_doc_id\": \"8y24j34j\", \"negative_doc_ids\": [\"9v4nlo8o\", \"tw057okg\", \"qgklt8wa\", \"kkga96h9\", \"1a0fj900\"]}\n",
            "{\"query\": \"How can individuals in social isolation maintain their mental well-being during COVID-19?\", \"positive_doc_id\": \"ue7c4fno\", \"negative_doc_ids\": [\"uhjp541j\", \"w3e6ul3v\", \"rs6hsy8u\", \"j7novgyb\", \"slbiz2vw\"]}\n",
            "{\"query\": \"What is the case presented involving a liver transplant donor and COVID-19?\", \"positive_doc_id\": \"dunxxu5r\", \"negative_doc_ids\": [\"r6kl7vb0\", \"6l7fwylu\", \"avfvpqs5\", \"owsoyvyz\", \"mgrxo21j\"]}\n",
            "{\"query\": \"What symptom has a high predictive value for COVID-19 diagnosis according to a cross-sectional observational study in Brazil?\", \"positive_doc_id\": \"8n7ot72s\", \"negative_doc_ids\": [\"x580ktas\", \"p1cuif8t\", \"ykl0xmta\", \"69x6jkp6\", \"tlg5mnvk\"]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "qxeuyDaj1hr9"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_val, Y_val = generate_training_data(\"concatenated.jsonl\", model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEZELqBfavb8",
        "outputId": "ba932bf7-86f6-4e63-95d0-b90d9e9a2899"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "                                               query  \\\n",
            "0  What is the most suitable protein for a diagno...   \n",
            "1  What is Cryptosporidium parvum and why is it a...   \n",
            "2  What is the role of the renin-angiotensin-aldo...   \n",
            "3  What are the functions of individual endolysos...   \n",
            "4  What is the prevalence of olfactory dysfunctio...   \n",
            "\n",
            "                                             passage  score  \n",
            "0  Rapid identification of novel antigens of Salm...   True  \n",
            "1  Cryptosporidium and host resistance: historica...   True  \n",
            "2  Understanding the Renin-Angiotensin-Aldosteron...   True  \n",
            "3  Specific functions of lysosomal proteases in e...   True  \n",
            "4  Olfactory and rhinological evaluations in SARS...   True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_queries = list(X_train[\"query\"])\n",
        "train_passages = list(X_train[\"passage\"])\n",
        "val_queries = list(X_val[\"query\"])\n",
        "val_passages = list(X_val[\"passage\"])"
      ],
      "metadata": {
        "id": "Zqt140-2a723"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA6R078shKqq",
        "outputId": "69088365-3fcd-42b2-d92c-088a5d1ec283"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31808"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-7746fThNmv",
        "outputId": "ddfb0512-4588-4aa0-9c84-ce92ac8b35cd"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3536"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = MSMARCODataset(tokenizer, train_queries, train_passages, Y_train)\n",
        "assert len(dataset_train[0]['input_ids']) > 0\n",
        "assert len(dataset_train[1]['attention_mask']) > 0"
      ],
      "metadata": {
        "id": "KRi4RLyChPjB"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_val = MSMARCODataset(tokenizer, val_queries, val_passages, Y_val)\n",
        "assert len(dataset_val[0]['input_ids']) > 0\n",
        "assert len(dataset_val[1]['attention_mask']) > 0"
      ],
      "metadata": {
        "id": "8k6YV2qThYzr"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils import data"
      ],
      "metadata": {
        "id": "7P9Z7asoHeDD"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataloader_train = data.DataLoader(dataset_train, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "dataloader_valid = data.DataLoader(dataset_val, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "4rPAnR12hdEf"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(model_name, 10, lr=3e-5)"
      ],
      "metadata": {
        "id": "ehAOwZ3oBKUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #model = AutoModelForSequenceClassification.from_pretrained(f'{MODELS_PATH}/best_checkpoint').to(device)\n",
        " model = AutoModelForSequenceClassification.from_pretrained(f'{MODELS_PATH}/best_checkpoint-cross-encoder').to(device)"
      ],
      "metadata": {
        "id": "v3E7Yl0Bifhw"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model=model, dataloader=dataloader_valid, set_name='Valid', model_name=model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "e3d889a6672c4013a085a3c7a7d5f4a0",
            "ff140cdf5e664938a0f198800bcd8053",
            "fd0a496432cb460dba23c824c020a855",
            "55a4ba923b17473c90521b34e3a52516",
            "712715bc339a4e048f1dc6fb2c72a8e5",
            "f552a5537da14a82927d4485eb8bdb35",
            "218dbdd0c2c0470eb744ff68619a4641",
            "cdc508b10a8d4072bb633d6a45b19021",
            "20d2f41b2ad34368aa39dad3f83efa73",
            "caa637729de74f30bbd49e7bcab855ee",
            "b357ef19bc2646e9ae23ba13ca9fca1c"
          ]
        },
        "id": "17HmddVh4ph5",
        "outputId": "5d7fa87d-9f72-4be2-bdc6-e203547b289b"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Valid:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3d889a6672c4013a085a3c7a7d5f4a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss: 0.030; Valid accuracy: 0.889\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8891402714932126"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit_scores = evaluate_test_dataset2(model=model, dataloader=dataloader_test, set_name='Test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "57ea49d4e59940c782fb1e5a65c52dd3",
            "420425348e9b47f0b64342cc9a2c3b9a",
            "4665565b20ef42d3a5ab89fb0fdd4aa3",
            "bbfabe3cc7b749c5a2eca48b6f71254d",
            "87bc8237661b4e55b126c1bd9a0092f2",
            "43318c11f40148e5b7bf9673fca67077",
            "1d91355cbf164f0f8ddc4de9899c0ba4",
            "1e93caa0572e4b528dcd166e1cbe8dbd",
            "3b289dde737143a19812681212f834ce",
            "4cb9d9fa9f18481eb498e2bd637fc703",
            "ef87405783454cde84c83ad6ffe8ca87"
          ]
        },
        "id": "mWvoXVB24ynY",
        "outputId": "41d631f8-33a3-4cbb-ce55-12fe864e9d84"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Test:   0%|          | 0/1563 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57ea49d4e59940c782fb1e5a65c52dd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trec_file_logits = evaluate_ndcg_10(logit_scores, model_name, \"logits\", query_ids, passage_ids)"
      ],
      "metadata": {
        "id": "uX4Zbmp55DcH"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "run_trec_file_logits = pd.read_csv(trec_file_logits, sep=\"\\t\", header=None, \n",
        "                   skiprows=1, names=[\"query\", \"docid\", \"rank\", \"score\", \"system\"])\n",
        "run_trec_file_logits[\"q0\"] = \"q0\"\n",
        "run_trec_file_logits = run_trec_file_logits.to_dict(orient=\"list\")"
      ],
      "metadata": {
        "id": "wGDDWRof5IBb"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_ndcg10(run_trec_file_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3eYbqE45Omi",
        "outputId": "b0030ca0-360e-4336-edff-209a3a5518bd"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7022291382541727"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lXZrtt0rG1kD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3d889a6672c4013a085a3c7a7d5f4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff140cdf5e664938a0f198800bcd8053",
              "IPY_MODEL_fd0a496432cb460dba23c824c020a855",
              "IPY_MODEL_55a4ba923b17473c90521b34e3a52516"
            ],
            "layout": "IPY_MODEL_712715bc339a4e048f1dc6fb2c72a8e5"
          }
        },
        "ff140cdf5e664938a0f198800bcd8053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f552a5537da14a82927d4485eb8bdb35",
            "placeholder": "​",
            "style": "IPY_MODEL_218dbdd0c2c0470eb744ff68619a4641",
            "value": "Valid: 100%"
          }
        },
        "fd0a496432cb460dba23c824c020a855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc508b10a8d4072bb633d6a45b19021",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20d2f41b2ad34368aa39dad3f83efa73",
            "value": 111
          }
        },
        "55a4ba923b17473c90521b34e3a52516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caa637729de74f30bbd49e7bcab855ee",
            "placeholder": "​",
            "style": "IPY_MODEL_b357ef19bc2646e9ae23ba13ca9fca1c",
            "value": " 111/111 [00:26&lt;00:00,  2.83it/s]"
          }
        },
        "712715bc339a4e048f1dc6fb2c72a8e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f552a5537da14a82927d4485eb8bdb35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "218dbdd0c2c0470eb744ff68619a4641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdc508b10a8d4072bb633d6a45b19021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d2f41b2ad34368aa39dad3f83efa73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "caa637729de74f30bbd49e7bcab855ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b357ef19bc2646e9ae23ba13ca9fca1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57ea49d4e59940c782fb1e5a65c52dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_420425348e9b47f0b64342cc9a2c3b9a",
              "IPY_MODEL_4665565b20ef42d3a5ab89fb0fdd4aa3",
              "IPY_MODEL_bbfabe3cc7b749c5a2eca48b6f71254d"
            ],
            "layout": "IPY_MODEL_87bc8237661b4e55b126c1bd9a0092f2"
          }
        },
        "420425348e9b47f0b64342cc9a2c3b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43318c11f40148e5b7bf9673fca67077",
            "placeholder": "​",
            "style": "IPY_MODEL_1d91355cbf164f0f8ddc4de9899c0ba4",
            "value": "Test: 100%"
          }
        },
        "4665565b20ef42d3a5ab89fb0fdd4aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e93caa0572e4b528dcd166e1cbe8dbd",
            "max": 1563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b289dde737143a19812681212f834ce",
            "value": 1563
          }
        },
        "bbfabe3cc7b749c5a2eca48b6f71254d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cb9d9fa9f18481eb498e2bd637fc703",
            "placeholder": "​",
            "style": "IPY_MODEL_ef87405783454cde84c83ad6ffe8ca87",
            "value": " 1563/1563 [07:09&lt;00:00,  4.26it/s]"
          }
        },
        "87bc8237661b4e55b126c1bd9a0092f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43318c11f40148e5b7bf9673fca67077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d91355cbf164f0f8ddc4de9899c0ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e93caa0572e4b528dcd166e1cbe8dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b289dde737143a19812681212f834ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cb9d9fa9f18481eb498e2bd637fc703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef87405783454cde84c83ad6ffe8ca87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
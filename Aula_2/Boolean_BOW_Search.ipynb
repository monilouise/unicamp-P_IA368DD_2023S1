{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDiqaFQPuNar"
      },
      "source": [
        "# Buscadores booleano e bag-of-words no TREC-DL 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxw_ExbPU6K9"
      },
      "source": [
        "Aqui, são implementado:\n",
        " \n",
        "*   um buscador booleano, que apenas leva em consideração a ocorrência ou não de cada termo da query em cada documento, independente do número de ocorrências de cada termo.\n",
        "*   um buscador baseado em bag-of-words, que leva em consideração o número de ocorrências de cada termo no documento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FtZGrPKuTwP"
      },
      "source": [
        "## Download do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBcnISueOtl-"
      },
      "source": [
        "Montagem local para acesso posterior aos arquivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkWo-SJ3uUe-",
        "outputId": "b588ba7c-3696-4009-ac68-12c652e6d35e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLcUasvzuXPB",
        "outputId": "7b06cf82-1774-4a09-91e2-66f6cc81ddcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diretório já existente\n"
          ]
        }
      ],
      "source": [
        "main_path = '/content/drive/MyDrive/Unicamp-aula-2/'\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(main_path):\n",
        "  os.makedirs(main_path)\n",
        "else:\n",
        "  print('Diretório já existente')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RLVOaq8TUJL"
      },
      "source": [
        "## Download de ferramentas auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de4PVG9zOpNK"
      },
      "source": [
        "Instalação do Pyserini para uso do Lucene Analyzer para fins de pré-processamento(tokenização, remoção de stopwords, stemming)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be_swSbxurh7",
        "outputId": "c689f422-faf3-48e2-c9ae-d7ed8f04f292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyserini\n",
            "  Downloading pyserini-0.20.0-py3-none-any.whl (137.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.1/137.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from pyserini) (1.10.1)\n",
            "Collecting lightgbm>=3.3.2\n",
            "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.9/dist-packages (from pyserini) (0.29.33)\n",
            "Collecting sentencepiece>=0.1.95\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.9/dist-packages (from pyserini) (1.2.1)\n",
            "Requirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.9/dist-packages (from pyserini) (3.4.4)\n",
            "Collecting pandas>=1.4.0\n",
            "  Downloading pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.9/dist-packages (from pyserini) (1.22.4)\n",
            "Collecting transformers>=4.6.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjnius>=1.4.0\n",
            "  Downloading pyjnius-1.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nmslib>=2.1.1\n",
            "  Downloading nmslib-2.1.1-cp39-cp39-manylinux2010_x86_64.whl (13.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.8.1\n",
            "  Downloading onnxruntime-1.14.1-cp39-cp39-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from pyserini) (4.65.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from lightgbm>=3.3.2->pyserini) (0.38.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 KB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.4.0->pyserini) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.4.0->pyserini) (2.8.2)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (0.7.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (2.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (3.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (2.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (1.0.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (6.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (1.10.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (3.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (3.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (2.4.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (2.25.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (3.0.12)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.6.0->pyserini) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.6.0->pyserini) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.6.0->pyserini) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 KB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.6.0->pyserini) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.2.1->pyserini) (8.1.3)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.2.1)\n",
            "Installing collected packages: tokenizers, sentencepiece, pyjnius, pybind11, humanfriendly, pandas, nmslib, huggingface-hub, coloredlogs, transformers, onnxruntime, lightgbm, pyserini\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed coloredlogs-15.0.1 huggingface-hub-0.13.0 humanfriendly-10.0 lightgbm-3.3.5 nmslib-2.1.1 onnxruntime-1.14.1 pandas-1.5.3 pybind11-2.6.1 pyjnius-1.4.2 pyserini-0.20.0 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyserini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ_RWu8bOkgN"
      },
      "source": [
        "Download de ferramentas para avaliação do TREC DL 2020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O97kuBrZTyZ6",
        "outputId": "babad047-95f9-43b8-cdd3-76e3f545eb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path '/content/drive/MyDrive/Unicamp-aula-2//pyserini' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/castorini/pyserini.git --recurse-submodules {main_path}/pyserini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjR4FDswUJeM",
        "outputId": "82c287ac-1c73-46cb-e40c-00686b6ef945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trec_eval.9.0.4/\n",
            "trec_eval.9.0.4/m_prefs_pair.c\n",
            "trec_eval.9.0.4/m_ndcg_p.c\n",
            "trec_eval.9.0.4/m_infap.c\n",
            "trec_eval.9.0.4/m_num_q.c\n",
            "trec_eval.9.0.4/m_iprec_at_recall.c\n",
            "trec_eval.9.0.4/form_prefs_counts.c\n",
            "trec_eval.9.0.4/m_prefs_num_prefs_ful_ret.c\n",
            "trec_eval.9.0.4/utility_pool.c\n",
            "trec_eval.9.0.4/m_binG.c\n",
            "trec_eval.9.0.4/meas_avg.c\n",
            "trec_eval.9.0.4/m_gm_bpref.c\n",
            "trec_eval.9.0.4/m_runid.c\n",
            "trec_eval.9.0.4/m_bpref.c\n",
            "trec_eval.9.0.4/m_gm_map.c\n",
            "trec_eval.9.0.4/trec_eval.h\n",
            "trec_eval.9.0.4/m_yaap.c\n",
            "trec_eval.9.0.4/m_relstring.c\n",
            "trec_eval.9.0.4/m_Rprec.c\n",
            "trec_eval.9.0.4/m_prefs_avgjg.c\n",
            "trec_eval.9.0.4/m_success.c\n",
            "trec_eval.9.0.4/m_ndcg.c\n",
            "trec_eval.9.0.4/functions.h\n",
            "trec_eval.9.0.4/m_P_avgjg.c\n",
            "trec_eval.9.0.4/test/\n",
            "trec_eval.9.0.4/test/qrels.rel_level\n",
            "trec_eval.9.0.4/test/results.test\n",
            "trec_eval.9.0.4/test/qrels.test\n",
            "trec_eval.9.0.4/test/out.test.qrels_jg\n",
            "trec_eval.9.0.4/test/out.test.meas_params\n",
            "trec_eval.9.0.4/test/out.test.a\n",
            "trec_eval.9.0.4/test/out.test.prefs\n",
            "trec_eval.9.0.4/test/out.test.aqcM\n",
            "trec_eval.9.0.4/test/out.test.aql\n",
            "trec_eval.9.0.4/test/prefs.test\n",
            "trec_eval.9.0.4/test/out.test\n",
            "trec_eval.9.0.4/test/out.test.aq\n",
            "trec_eval.9.0.4/test/out.test.aqc\n",
            "trec_eval.9.0.4/test/out.test.qrels_prefs\n",
            "trec_eval.9.0.4/test/zscores_file\n",
            "trec_eval.9.0.4/test/qrels.123\n",
            "trec_eval.9.0.4/test/out.test.aqZ\n",
            "trec_eval.9.0.4/test/results.trunc\n",
            "trec_eval.9.0.4/test/prefs.results.test\n",
            "trec_eval.9.0.4/test/prefs.rank20\n",
            "trec_eval.9.0.4/m_11pt_avg.c\n",
            "trec_eval.9.0.4/m_G.c\n",
            "trec_eval.9.0.4/m_num_rel.c\n",
            "trec_eval.9.0.4/m_map_cut.c\n",
            "trec_eval.9.0.4/m_prefs_avgjg_ret.c\n",
            "trec_eval.9.0.4/m_Rprec_mult.c\n",
            "trec_eval.9.0.4/Makefile\n",
            "trec_eval.9.0.4/m_map_avgjg.c\n",
            "trec_eval.9.0.4/get_qrels_prefs.c\n",
            "trec_eval.9.0.4/README\n",
            "trec_eval.9.0.4/m_set_rel_P.c\n",
            "trec_eval.9.0.4/sysfunc.h\n",
            "trec_eval.9.0.4/m_prefs_pair_ret.c\n",
            "trec_eval.9.0.4/convert_zscores.c\n",
            "trec_eval.9.0.4/m_ndcg_cut.c\n",
            "trec_eval.9.0.4/m_prefs_pair_imp.c\n",
            "trec_eval.9.0.4/meas_print_single.c\n",
            "trec_eval.9.0.4/meas_print_final.c\n",
            "trec_eval.9.0.4/trec_eval.c\n",
            "trec_eval.9.0.4/m_num_ret.c\n",
            "trec_eval.9.0.4/get_prefs.c\n",
            "trec_eval.9.0.4/m_P.c\n",
            "trec_eval.9.0.4/get_qrels_jg.c\n",
            "trec_eval.9.0.4/m_rel_P.c\n",
            "trec_eval.9.0.4/meas_acc.c\n",
            "trec_eval.9.0.4/m_prefs_simp.c\n",
            "trec_eval.9.0.4/m_recall.c\n",
            "trec_eval.9.0.4/trec_format.h\n",
            "trec_eval.9.0.4/m_ndcg_rel.c\n",
            "trec_eval.9.0.4/m_num_nonrel_judged_ret.c\n",
            "trec_eval.9.0.4/formats.c\n",
            "trec_eval.9.0.4/bpref_bug\n",
            "trec_eval.9.0.4/README.windows.md\n",
            "trec_eval.9.0.4/m_prefs_num_prefs_ful.c\n",
            "trec_eval.9.0.4/m_set_map.c\n",
            "trec_eval.9.0.4/get_qrels.c\n",
            "trec_eval.9.0.4/m_set_F.c\n",
            "trec_eval.9.0.4/measures.c\n",
            "trec_eval.9.0.4/common.h\n",
            "trec_eval.9.0.4/meas_init.c\n",
            "trec_eval.9.0.4/m_recip_rank.c\n",
            "trec_eval.9.0.4/m_set_recall.c\n",
            "trec_eval.9.0.4/get_trec_results.c\n",
            "trec_eval.9.0.4/m_prefs_simp_ret.c\n",
            "trec_eval.9.0.4/m_num_rel_ret.c\n",
            "trec_eval.9.0.4/m_map.c\n",
            "trec_eval.9.0.4/m_utility.c\n",
            "trec_eval.9.0.4/form_res_rels.c\n",
            "trec_eval.9.0.4/form_res_rels_jg.c\n",
            "trec_eval.9.0.4/m_prefs_simp_imp.c\n",
            "trec_eval.9.0.4/m_prefs_num_prefs_poss.c\n",
            "trec_eval.9.0.4/m_prefs_avgjg_Rnonrel.c\n",
            "trec_eval.9.0.4/m_prefs_avgjg_Rnonrel_ret.c\n",
            "trec_eval.9.0.4/m_set_P.c\n",
            "trec_eval.9.0.4/m_prefs_avgjg_imp.c\n",
            "trec_eval.9.0.4/m_Rndcg.c\n",
            "trec_eval.9.0.4/CHANGELOG\n",
            "trec_eval.9.0.4/m_Rprec_mult_avgjg.c\n",
            "trec_eval.9.0.4/get_zscores.c\n",
            "make: 'trec_eval' is up to date.\n",
            "make: 'ndeval' is up to date.\n"
          ]
        }
      ],
      "source": [
        "!cd {main_path}/pyserini/tools/eval && tar xvfz trec_eval.9.0.4.tar.gz && cd trec_eval.9.0.4 && make && cd ../../..\n",
        "!cd {main_path}/pyserini/tools/eval/ndeval && make && cd ../../.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmvMxtynTmKC"
      },
      "source": [
        "## Construção dos índice invertidos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialmente foi construído um índice invertido apenas para a busca booleana, que foi utilizado em seguida para os tetes.  \n",
        "\n",
        "Posteriormente, foi acrescentado um índice invertido para buscas do tipo bag-of-words, onde a única diferença em relação à busca booleana é que é levada em consideração o número de vezes em que cada termo ocorre em cada documento, enquanto na booleana apenas a presença de cada termo da busca é checada."
      ],
      "metadata": {
        "id": "5ST3cE287lZj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cCpsvCE7u0o7"
      },
      "outputs": [],
      "source": [
        "from pyserini.analysis import Analyzer, get_lucene_analyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSMFneIku5L3",
        "outputId": "5713c6a6-2bed-4f4f-95da-fa080e7d90b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgzdbKNEONqb"
      },
      "source": [
        "Código para pré-processamento textual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "49JWfNjWu8ZJ"
      },
      "outputs": [],
      "source": [
        "analyzer = Analyzer(get_lucene_analyzer())\n",
        "\n",
        "def preprocess_and_tokenize(text):\n",
        "  return analyzer.analyze(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kwy8QAUCvBi1"
      },
      "outputs": [],
      "source": [
        "collection_path = main_path + '/collections/msmarco-passage/collection.tsv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbJo3TZZOI8k"
      },
      "source": [
        "Foi verificado que o analisador do Lucene não elimina suficientemente stopwords.  Assim, foi utilizada adicionalmente a lista de stopwords do NLTK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhc11tGLJPWe",
        "outputId": "c9a86b19-3112-411e-f5ca-530043388d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import string\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "nltk.download('stopwords')  # Download stopwords if not already downloaded\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words = set(stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT-j7gpNfbP0"
      },
      "source": [
        "Em seguida, será construído o índice invertido para associar os tokens aos documentos nos quais eles ocorrem.  O uso da estrutura de dados array (sugestão do colega [Leandro Carísio](https://colab.research.google.com/drive/1hELJYqsvUyja9HPeDzc9FU8okqdIjODE?usp=sharing)) resultou em um ganho relevante em memória em relação a listas.  Tal estrutura de dados, ao contrário dos arrays do Numpy, assemelha-se a um array dinâmico, ou lista, porém ocupa bem menos memória."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Índice invertido para busca booleana:"
      ],
      "metadata": {
        "id": "E7p7UbYv8L3s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8GurqwF5yhX",
        "outputId": "c0858e5e-6a49-499e-b107-fbd7829ad393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading index...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import array\n",
        "import pickle\n",
        "\n",
        "index_path = f\"{main_path}/inverted_index_boolean.pickle\"\n",
        "\n",
        "if os.path.exists(index_path):\n",
        "    with open(index_path, \"rb\") as f:\n",
        "      print(\"Loading index...\")\n",
        "      inverted_index_boolean = pickle.load(f)\n",
        "else:\n",
        "  # set the chunk size\n",
        "  chunk_size = 1000\n",
        "  chunks = []\n",
        "  inverted_index_boolean = dict()\n",
        "  full_text = ''\n",
        "\n",
        "  def process(row):\n",
        "    tokenized_text = preprocess_and_tokenize(row[1])\n",
        "    doc_id = row[0]\n",
        "    for token in tokenized_text:\n",
        "      if token not in stop_words:\n",
        "        inverted_index_boolean.setdefault(token, array.array(\"L\", [])).append(int(doc_id))\n",
        "\n",
        "  chunk_id = 0\n",
        "  # iterate through the file in chunks\n",
        "  for chunk in pd.read_csv(collection_path, sep='\\t', header=None, chunksize=chunk_size):\n",
        "    # process the chunk here\n",
        "    if (chunk_id % 1000) == 0:\n",
        "      print(f'Processing chunk {chunk_id}')\n",
        "    for index, row in chunk.iterrows():\n",
        "      process(row)\n",
        "    del(chunk)\n",
        "    chunk_id += 1\n",
        "\n",
        "  with open(index_path, \"wb\") as f:\n",
        "    pickle.dump(inverted_index_boolean, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Índice invertido para busca baseada em bag-of-words:"
      ],
      "metadata": {
        "id": "cLQRuTbh8QAn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg7zspUeS1-c",
        "outputId": "2b43e770-f740-45c9-ac40-60e597f84661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading index...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import array\n",
        "import pickle\n",
        "from collections import Counter\n",
        "\n",
        "index_path = f\"{main_path}/inverted_index_bow.pickle\"\n",
        "\n",
        "if os.path.exists(index_path):\n",
        "    with open(index_path, \"rb\") as f:\n",
        "      print(\"Loading index...\")\n",
        "      inverted_index_bow = pickle.load(f)\n",
        "else:\n",
        "  # set the chunk size\n",
        "  chunk_size = 1000\n",
        "  chunks = []\n",
        "  inverted_index_bow = dict()\n",
        "  full_text = ''\n",
        "\n",
        "  def process(row):\n",
        "    tokenized_text = preprocess_and_tokenize(row[1])\n",
        "    counter = Counter(tokenized_text)\n",
        "    doc_id = row[0]\n",
        "    for token, count in counter.items():\n",
        "      if token not in stop_words:\n",
        "        inverted_index_bow.setdefault(token, {\"docs\":array.array(\"L\", []), \"counts\":array.array(\"f\", [])})[\"docs\"].append(int(doc_id))\n",
        "        inverted_index_bow.setdefault(token, {\"docs\":array.array(\"L\", []), \"counts\":array.array(\"L\", [])})[\"counts\"].append(count)\n",
        "\n",
        "  chunk_id = 0\n",
        "  # iterate through the file in chunks\n",
        "  for chunk in pd.read_csv(collection_path, sep='\\t', header=None, chunksize=chunk_size):\n",
        "    # process the chunk here\n",
        "    if (chunk_id % 1000) == 0:\n",
        "      print(f'Processing chunk {chunk_id}')\n",
        "    for index, row in chunk.iterrows():\n",
        "      process(row)\n",
        "    del(chunk)\n",
        "    chunk_id += 1\n",
        "\n",
        "  with open(index_path, \"wb\") as f:\n",
        "    pickle.dump(inverted_index_bow, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(inverted_index_boolean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiXtbxL8o_Y1",
        "outputId": "fdb8149a-78f3-4118-a25d-7c7a86aa1a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2660662"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD1BrbHRvMDL"
      },
      "outputs": [],
      "source": [
        "assert len(inverted_index_boolean) == len(inverted_index_bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqUvI7BC5VHw",
        "outputId": "4456b0d1-1a3d-4c91-b4f4-671b97c530fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\tThe presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.\n",
            "1\tThe Manhattan Project and its atomic bomb helped bring an end to World War II. Its legacy of peaceful uses of atomic energy continues to have an impact on history and science.\n",
            "2\tEssay on The Manhattan Project - The Manhattan Project The Manhattan Project was to see if making an atomic bomb possible. The success of this project would forever change the world forever making it known that something this powerful can be manmade.\n",
            "3\tThe Manhattan Project was the name for a project conducted during World War II, to develop the first atomic bomb. It refers specifically to the period of the project from 194 â¦ 2-1946 under the control of the U.S. Army Corps of Engineers, under the administration of General Leslie R. Groves.\n",
            "4\tversions of each volume as well as complementary websites. The first websiteâThe Manhattan Project: An Interactive Historyâis available on the Office of History and Heritage Resources website, http://www.cfo. doe.gov/me70/history. The Office of History and Heritage Resources and the National Nuclear Security\n",
            "5\tThe Manhattan Project. This once classified photograph features the first atomic bomb â a weapon that atomic scientists had nicknamed Gadget.. The nuclear age began on July 16, 1945, when it was detonated in the New Mexico desert.\n",
            "6\tNor will it attempt to substitute for the extraordinarily rich literature on the atomic bombs and the end of World War II. This collection does not attempt to document the origins and development of the Manhattan Project.\n",
            "7\tManhattan Project. The Manhattan Project was a research and development undertaking during World War II that produced the first nuclear weapons. It was led by the United States with the support of the United Kingdom and Canada. From 1942 to 1946, the project was under the direction of Major General Leslie Groves of the U.S. Army Corps of Engineers. Nuclear physicist Robert Oppenheimer was the director of the Los Alamos Laboratory that designed the actual bombs. The Army component of the project was designated the\n",
            "8\tIn June 1942, the United States Army Corps of Engineersbegan the Manhattan Project- The secret name for the 2 atomic bombs.\n",
            "9\tOne of the main reasons Hanford was selected as a site for the Manhattan Project's B Reactor was its proximity to the Columbia River, the largest river flowing into the Pacific Ocean from the North American coast.\n"
          ]
        }
      ],
      "source": [
        "!head {collection_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4t5V238T7d6"
      },
      "source": [
        "## Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aiujR-Y6KUtf"
      },
      "outputs": [],
      "source": [
        "topics_file = main_path + '/pyserini/tools/topics-and-qrels/topics.dl20.txt'\n",
        "qrels_eval = main_path + '/pyserini/tools/topics-and-qrels/qrels.dl20-passage.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F0hqvNoLta6",
        "outputId": "715b8d49-20a2-47f1-ee9e-1464d43c799d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1030303\twho is aziz hashim\r\n",
            "1037496\twho is rep scalise?\r\n",
            "1043135\twho killed nicholas ii of russia\r\n",
            "1045109\twho owns barnhart crane\r\n",
            "1049519\twho said no one can make you feel inferior\r\n",
            "1051399\twho sings monk theme song\r\n",
            "1056416\twho was the highest career passer  rating in the nfl\r\n",
            "1064670\twhy do hunters pattern their shotguns?\r\n",
            "1065636\twhy do some places on my scalp feel sore\r\n",
            "1071750\twhy is pete rose banned from hall of fame\r\n"
          ]
        }
      ],
      "source": [
        "!head {topics_file}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ8H_jWOfBMs",
        "outputId": "989dd137-77ec-4cc2-d547-29931f3eca85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23849 0 1020327 2\n",
            "23849 0 1034183 3\n",
            "23849 0 1120730 0\n",
            "23849 0 1139571 1\n",
            "23849 0 1143724 0\n",
            "23849 0 1147202 0\n",
            "23849 0 1150311 0\n",
            "23849 0 1158886 2\n",
            "23849 0 1175024 1\n",
            "23849 0 1201385 0\n"
          ]
        }
      ],
      "source": [
        "!head {qrels_eval}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lógica de busca booleana"
      ],
      "metadata": {
        "id": "sOfFDIAg-7gN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1VjKwZJMLvgI"
      },
      "outputs": [],
      "source": [
        "def search_boolean(query, use_stopwords=False):\n",
        "  doc_scores = defaultdict(int) # int (doc_id) -> int (score)\n",
        "  query_tokens = preprocess_and_tokenize(query)\n",
        "  query_counter = Counter(query_tokens)\n",
        "\n",
        "  for token in query_counter.keys():\n",
        "    if token in inverted_index_boolean:\n",
        "      doc_ids = set(inverted_index_boolean[token])\n",
        "      for doc_id in doc_ids:\n",
        "        doc_scores[doc_id] += 1\n",
        "\n",
        "  return doc_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lógica de busca baseada em bag-of-words"
      ],
      "metadata": {
        "id": "yl2Ujnnl_ATj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2EAthzlxTvtz"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def search_bow(query):\n",
        "  doc_scores = defaultdict(int) # int (doc_id) -> int (score)\n",
        "  query_tokens = preprocess_and_tokenize(query)\n",
        "  n_query_tokens = len(query_tokens)\n",
        "  query_counter = Counter(query_tokens)\n",
        "\n",
        "  for token in query_counter.keys():\n",
        "    if token in inverted_index_bow:\n",
        "      doc_ids = inverted_index_bow[token][\"docs\"]\n",
        "\n",
        "      for i, doc_id in enumerate(doc_ids):\n",
        "        doc_scores[doc_id] += inverted_index_bow[token][\"counts\"][i]\n",
        "    \n",
        "          \n",
        "  return doc_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yfHwaJWhNYBF"
      },
      "outputs": [],
      "source": [
        "results_boolean = search_boolean('who is aziz hashim', True)\n",
        "results_bow = search_bow('who is aziz hashim')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0nNth1oNnNe",
        "outputId": "94dd35da-7b98-41a3-d527-e724b078dfe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245\n",
            "245\n"
          ]
        }
      ],
      "source": [
        "print(len(results_boolean))\n",
        "print(len(results_bow))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eExn_oy6Wh3w"
      },
      "outputs": [],
      "source": [
        "def get_document_by_id(id):\n",
        "  result = None\n",
        "  with open(collection_path, 'r') as f:\n",
        "    for line in f:\n",
        "      fields = line.strip().split('\\t')\n",
        "      doc_id = fields[0]\n",
        "      if doc_id == id:\n",
        "        result = fields[1]\n",
        "        break\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "A0O3yBIEYXDg"
      },
      "outputs": [],
      "source": [
        "sorted_results_boolean = sorted(results_boolean.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "sorted_results_bow = sorted(results_bow.items(), key=lambda x: x[1], reverse=True)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_results_boolean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygBHng8X9OT4",
        "outputId": "e656f629-bdc9-41ff-a840-2df47b714063"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(7156982, 2),\n",
              " (8726429, 2),\n",
              " (8726430, 2),\n",
              " (8726433, 2),\n",
              " (8726434, 2),\n",
              " (8726435, 2),\n",
              " (8726436, 2),\n",
              " (8726437, 2),\n",
              " (794624, 1),\n",
              " (4820481, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_results_bow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsr6OT0z9Q2H",
        "outputId": "65c6537f-494d-4a03-9ea0-3ff3f1015601"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(8726436, 8.0),\n",
              " (1305520, 6.0),\n",
              " (1305521, 6.0),\n",
              " (6222298, 5.0),\n",
              " (1451846, 4.0),\n",
              " (1905988, 3.0),\n",
              " (2699097, 3.0),\n",
              " (6764572, 3.0),\n",
              " (6939422, 3.0),\n",
              " (6939426, 3.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "xnUN599MY5XY",
        "outputId": "d8e55672-f0a4-41a0-ddfd-340c772250b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Abdul Aziz (Arabic: Ø¹Ø¨Ø¯ Ø§Ù\\x84Ø¹Ø²Ù\\x8aØ² â\\x80\\x8e) is a male Muslim given name and in modern usage, surname. It is built from the Arabic words Abd, al-and Aziz.The name means servant of the Almighty, Al-AzÄ«z being one of the names of God in the Qur'an, which give rise to the Muslim theophoric names.bdul Aziz (Arabic: Ø¹Ø¨Ø¯ Ø§Ù\\x84Ø¹Ø²Ù\\x8aØ² â\\x80\\x8e) is a male Muslim given name and in modern usage, surname. It is built from the Arabic words Abd, al-and Aziz.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "get_document_by_id('6939426')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpIDJ4eeNDBz"
      },
      "source": [
        "As próximas células executam as rotinas de preparação e cálculo das métricas segundo o dataset de teste do TREC DL 2020."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 {main_path}/pyserini/tools/scripts/msmarco/filter_queries.py \\\n",
        "--qrels <(sed -e 's/ /\\t/g' {qrels_eval}) \\\n",
        "--queries {topics_file} \\\n",
        "--output topics.dl20.small.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avc8x5_LrTVP",
        "outputId": "d309455f-5ea8-446b-b050-978a9e87e007"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics_file = 'topics.dl20.small.tsv'"
      ],
      "metadata": {
        "id": "GhTBs8kTtHbP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cLL1cRNcZAt2"
      },
      "outputs": [],
      "source": [
        "query_to_results_boolean = dict()\n",
        "query_to_results_bow = dict()\n",
        "\n",
        "with open(topics_file, 'r') as f:\n",
        "  for line in f:\n",
        "      fields = line.strip().split('\\t')\n",
        "      query_id = fields[0]\n",
        "      query_text = fields[1]\n",
        "      results_boolean = search_boolean(query_text)\n",
        "      query_to_results_boolean[int(query_id)] = sorted(results_boolean.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "      results_bow = search_bow(query_text)\n",
        "      query_to_results_bow[int(query_id)] = sorted(results_bow.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "with open('run.dl20.boolean.trec', 'w') as f:\n",
        "  for query_id, results in query_to_results_boolean.items():\n",
        "    for i, (doc_id, score) in enumerate(results):\n",
        "      f.write(f'{query_id}\\tQ0\\t{doc_id}\\t{i+1}\\t{score}\\tboolean\\n')\n",
        "\n",
        "with open('run.dl20.bow.trec', 'w') as f:\n",
        "  for query_id, results in query_to_results_bow.items():\n",
        "    for i, (doc_id, score) in enumerate(results):\n",
        "      f.write(f'{query_id}\\tQ0\\t{doc_id}\\t{i+1}\\t{score}\\tbow\\n')\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiRHnKrlFPyw",
        "outputId": "d648a53c-0f94-4238-e207-16ba844f1f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1030303\tQ0\t7156982\t1\t2\tboolean\n",
            "1030303\tQ0\t8726429\t2\t2\tboolean\n",
            "1030303\tQ0\t8726430\t3\t2\tboolean\n",
            "1030303\tQ0\t8726433\t4\t2\tboolean\n",
            "1030303\tQ0\t8726434\t5\t2\tboolean\n",
            "1030303\tQ0\t8726435\t6\t2\tboolean\n",
            "1030303\tQ0\t8726436\t7\t2\tboolean\n",
            "1030303\tQ0\t8726437\t8\t2\tboolean\n",
            "1030303\tQ0\t794624\t9\t1\tboolean\n",
            "1030303\tQ0\t4820481\t10\t1\tboolean\n"
          ]
        }
      ],
      "source": [
        "!head run.dl20.boolean.trec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u51xHcmNGJ2i",
        "outputId": "27a61ecf-a537-4166-f1cc-f68fdd52f700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "!python {main_path}/pyserini/tools/scripts/msmarco/convert_msmarco_to_trec_qrels.py \\\n",
        "   --input {qrels_eval} \\\n",
        "   --output qrels.dl20.trec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtocDxsYHZDV",
        "outputId": "86b3c86d-02b0-42ba-ae05-c0071191b4c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23849 0 1020327 2\n",
            "23849 0 1034183 3\n",
            "23849 0 1120730 0\n",
            "23849 0 1139571 1\n",
            "23849 0 1143724 0\n",
            "23849 0 1147202 0\n",
            "23849 0 1150311 0\n",
            "23849 0 1158886 2\n",
            "23849 0 1175024 1\n",
            "23849 0 1201385 0\n"
          ]
        }
      ],
      "source": [
        "!head qrels.dl20.trec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4Z9tHIsJfLpo"
      },
      "outputs": [],
      "source": [
        "!chmod 755 {main_path}/pyserini/tools/eval/trec_eval.9.0.4/trec_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas para busca booleana"
      ],
      "metadata": {
        "id": "YkFoTW7h_M65"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMNRIGZZHpu6",
        "outputId": "9a807bc5-be14-487b-ca4b-95dd20798cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "map                   \tall\t0.1117\n",
            "ndcg_cut_10           \tall\t0.3189\n"
          ]
        }
      ],
      "source": [
        "!{main_path}/pyserini/tools/eval/trec_eval.9.0.4/trec_eval -c -m map -m ndcg_cut.10 -l 2 \\\n",
        "   qrels.dl20.trec run.dl20.boolean.trec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas para busca baseada em bag-of-words"
      ],
      "metadata": {
        "id": "ncNHNfSa_Py5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{main_path}/pyserini/tools/eval/trec_eval.9.0.4/trec_eval -c -m map -m ndcg_cut.10 -l 2 \\\n",
        "   qrels.dl20.trec run.dl20.bow.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbsplKwo5JEp",
        "outputId": "15f51919-6c98-44af-8f73-f4c3a80634a9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "map                   \tall\t0.0153\n",
            "ndcg_cut_10           \tall\t0.0492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xW-HysfZ4dgQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}